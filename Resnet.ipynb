{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6/V7eLi/h5oID470wdo+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeSotoG/U-Net-ResNetBlocks/blob/main/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcH2AvTh97gF"
      },
      "source": [
        "##Descarga datos\n",
        "Los datos se encuentran en el drive, por lo que usara gdown para sacarlos directamente y no tener que hacer la coneccion, ya que estamos descargando un zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7GLXIiagwH3",
        "outputId": "341793f0-4363-44a8-8a52-bfed82bef95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt\n",
            "To: /content/input.zip\n",
            "100% 597M/597M [00:04<00:00, 120MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uq8I6BfRhogZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H9Y2Q3Bce47L"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_jqAPlaMKtpg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hmJoArAEd41C"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  X[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)\n",
        "mas=\"/masks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  Y[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Borrar directorio /input en caso de error"
      ],
      "metadata": {
        "id": "3NcX5DC3VvAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/input"
      ],
      "metadata": {
        "id": "-QywVJIaZjHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6IAoTKTuO5B"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ub5XKwbdAQ32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.3, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resnet"
      ],
      "metadata": {
        "id": "P6CambWxdEwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6 \n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ],
      "metadata": {
        "id": "Urgfb0zMWlz-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_e_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return (c,s)"
      ],
      "metadata": {
        "id": "QrTMap7feMSc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wkYpNCf-ezrY"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([s,c])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_u_block(X,f,I,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Add()([I,c])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c"
      ],
      "metadata": {
        "id": "JTMBUM6DfO9a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "#Contraction path\n",
        "c1,z1 = conv_e_block(s,[8,8,16])\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2,z2 = conv_e_block(c1,[16,16,32])\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3,z3 = conv_e_block(c2,[32,32,64],0.2)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4,z4 = conv_e_block(c3,[64,64,128],0.2)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = conv_block(p4,[128,128,256],0.3)\n",
        "\n",
        "\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "c6 = conv_u_block(u6,[64,64,128],z4,0.2)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(1, 1), padding='same')(c6)\n",
        "c7 = conv_u_block(u7,[32,32,64],z3,0.2)\n",
        "\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(1, 1), padding='same')(c7)\n",
        "c8 = conv_u_block(u8,[16,16,32],z2)\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(1, 1), padding='same')(c8)\n",
        "c9 = conv_u_block(u9,[8,8,16],z1)\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgI54ahHeta-",
        "outputId": "38d70ab6-5d68-4181-bc33-dfee8918a0e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 128, 128, 1)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 128, 8)  16          ['lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 128, 8)  32         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 128, 8)  584         ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 128, 8)  32         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 128, 128, 16  144         ['dropout_19[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 128, 16  64         ['conv2d_35[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)                 (None, 128, 128, 16  0           ['batch_normalization_34[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 128, 128, 16  272         ['re_lu_9[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 128, 128, 16  64         ['conv2d_37[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_36[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_20[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 128, 128, 16  64         ['conv2d_38[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_37[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 128, 128, 32  544         ['dropout_21[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 128, 128, 32  128        ['conv2d_39[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_38[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 128, 128, 32  1056        ['re_lu_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 128, 128, 32  128        ['conv2d_41[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_40[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_22[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 128, 128, 32  128        ['conv2d_42[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_41[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 128, 128, 64  2112        ['dropout_23[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 128, 128, 64  256        ['conv2d_43[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)                (None, 128, 128, 64  0           ['batch_normalization_42[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 128, 128, 64  4160        ['re_lu_11[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 128, 128, 64  256        ['conv2d_45[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_44[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 128, 128, 64  36928       ['dropout_24[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 128, 128, 64  256        ['conv2d_46[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_25 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_45[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 128, 128, 12  8320        ['dropout_25[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 128, 128, 12  512        ['conv2d_47[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)                (None, 128, 128, 12  0           ['batch_normalization_46[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 64, 64, 128)  0          ['re_lu_12[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 64, 64, 128)  16512       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 64, 64, 128)  512        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)           (None, 64, 64, 128)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 64, 64, 128)  147584      ['dropout_26[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 64, 64, 128)  512        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)           (None, 64, 64, 128)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 64, 64, 256)  33024       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 64, 64, 256)  33024       ['dropout_27[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 64, 64, 256)  0           ['batch_normalization_51[0][0]', \n",
            "                                                                  'batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)                (None, 64, 64, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 128, 128, 12  131200     ['re_lu_13[0][0]']               \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 128, 128, 64  8256        ['conv2d_transpose_4[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 128, 128, 64  256        ['conv2d_53[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_52[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 128, 128, 64  36928       ['dropout_28[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 128, 128, 64  256        ['conv2d_54[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_53[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 128, 128, 12  8320        ['re_lu_11[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 128, 128, 12  8320        ['dropout_29[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 128, 128, 12  512        ['conv2d_48[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 128, 128, 12  512        ['conv2d_55[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 128, 128, 12  0           ['batch_normalization_47[0][0]', \n",
            "                                8)                                'batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)                (None, 128, 128, 12  0           ['add_6[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2DTran  (None, 128, 128, 64  32832      ['re_lu_14[0][0]']               \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 128, 128, 32  2080        ['conv2d_transpose_5[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 128, 128, 32  128        ['conv2d_56[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_55[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_30[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 128, 128, 32  128        ['conv2d_57[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_56[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 128, 128, 64  2112        ['re_lu_10[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 128, 128, 64  2112        ['dropout_31[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 128, 128, 64  256        ['conv2d_44[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 128, 128, 64  256        ['conv2d_58[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_43[0][0]', \n",
            "                                )                                 'batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)                (None, 128, 128, 64  0           ['add_7[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2DTran  (None, 128, 128, 32  8224       ['re_lu_15[0][0]']               \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 128, 128, 16  528         ['conv2d_transpose_6[0][0]']     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 128, 128, 16  64         ['conv2d_59[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_58[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_32[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 128, 128, 16  64         ['conv2d_60[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_59[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 128, 128, 32  544         ['re_lu_9[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 128, 128, 32  544         ['dropout_33[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 128, 128, 32  128        ['conv2d_40[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 128, 128, 32  128        ['conv2d_61[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 128, 128, 32  0           ['batch_normalization_39[0][0]', \n",
            "                                )                                 'batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_16 (ReLU)                (None, 128, 128, 32  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2DTran  (None, 128, 128, 16  2064       ['re_lu_16[0][0]']               \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 128, 128, 8)  136         ['conv2d_transpose_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 128, 128, 8)  32         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 128, 128, 8)  584         ['dropout_34[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 128, 128, 8)  32         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 128, 128, 16  32          ['lambda_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 128, 128, 16  144         ['dropout_35[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128, 128, 16  64         ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 128, 128, 16  64         ['conv2d_64[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 128, 128, 16  0           ['batch_normalization_35[0][0]', \n",
            "                                )                                 'batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_17 (ReLU)                (None, 128, 128, 16  0           ['add_9[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 128, 128, 1)  17          ['re_lu_17[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 560,265\n",
            "Trainable params: 556,329\n",
            "Non-trainable params: 3,936\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Fit"
      ],
      "metadata": {
        "id": "4JFyLMRezeWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,batch_size=16,epochs=25,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCB8atJ1zda4",
        "outputId": "020777aa-ebae-4952-b1a7-1d68dc7e636a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "124/124 [==============================] - 42s 199ms/step - loss: 0.1867 - accuracy: 0.9482 - DiceMetric: 0.1254 - val_loss: 0.1328 - val_accuracy: 0.9854 - val_DiceMetric: 0.1695\n",
            "Epoch 2/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0577 - accuracy: 0.9870 - DiceMetric: 0.2270 - val_loss: 0.0659 - val_accuracy: 0.9855 - val_DiceMetric: 0.2629\n",
            "Epoch 3/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0365 - accuracy: 0.9871 - DiceMetric: 0.4277 - val_loss: 0.0342 - val_accuracy: 0.9852 - val_DiceMetric: 0.5061\n",
            "Epoch 4/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0271 - accuracy: 0.9873 - DiceMetric: 0.5306 - val_loss: 0.0309 - val_accuracy: 0.9839 - val_DiceMetric: 0.5500\n",
            "Epoch 5/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0227 - accuracy: 0.9874 - DiceMetric: 0.5844 - val_loss: 0.0233 - val_accuracy: 0.9866 - val_DiceMetric: 0.6061\n",
            "Epoch 6/25\n",
            "124/124 [==============================] - 22s 180ms/step - loss: 0.0204 - accuracy: 0.9875 - DiceMetric: 0.6155 - val_loss: 0.0193 - val_accuracy: 0.9866 - val_DiceMetric: 0.6769\n",
            "Epoch 7/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0182 - accuracy: 0.9878 - DiceMetric: 0.6631 - val_loss: 0.0170 - val_accuracy: 0.9871 - val_DiceMetric: 0.7217\n",
            "Epoch 8/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0170 - accuracy: 0.9879 - DiceMetric: 0.6855 - val_loss: 0.0175 - val_accuracy: 0.9871 - val_DiceMetric: 0.7093\n",
            "Epoch 9/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0169 - accuracy: 0.9878 - DiceMetric: 0.6831 - val_loss: 0.0169 - val_accuracy: 0.9862 - val_DiceMetric: 0.7319\n",
            "Epoch 10/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0177 - accuracy: 0.9876 - DiceMetric: 0.6550 - val_loss: 0.0169 - val_accuracy: 0.9865 - val_DiceMetric: 0.7322\n",
            "Epoch 11/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0153 - accuracy: 0.9880 - DiceMetric: 0.7261 - val_loss: 0.0152 - val_accuracy: 0.9868 - val_DiceMetric: 0.7705\n",
            "Epoch 12/25\n",
            "124/124 [==============================] - 22s 178ms/step - loss: 0.0144 - accuracy: 0.9881 - DiceMetric: 0.7448 - val_loss: 0.0153 - val_accuracy: 0.9865 - val_DiceMetric: 0.7804\n",
            "Epoch 13/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0137 - accuracy: 0.9882 - DiceMetric: 0.7609 - val_loss: 0.0146 - val_accuracy: 0.9871 - val_DiceMetric: 0.7990\n",
            "Epoch 14/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0133 - accuracy: 0.9883 - DiceMetric: 0.7675 - val_loss: 0.0154 - val_accuracy: 0.9875 - val_DiceMetric: 0.7849\n",
            "Epoch 15/25\n",
            "124/124 [==============================] - 22s 178ms/step - loss: 0.0132 - accuracy: 0.9884 - DiceMetric: 0.7736 - val_loss: 0.0142 - val_accuracy: 0.9866 - val_DiceMetric: 0.7994\n",
            "Epoch 16/25\n",
            "124/124 [==============================] - 22s 178ms/step - loss: 0.0127 - accuracy: 0.9884 - DiceMetric: 0.7840 - val_loss: 0.0138 - val_accuracy: 0.9868 - val_DiceMetric: 0.8049\n",
            "Epoch 17/25\n",
            "124/124 [==============================] - 22s 178ms/step - loss: 0.0122 - accuracy: 0.9885 - DiceMetric: 0.7994 - val_loss: 0.0133 - val_accuracy: 0.9875 - val_DiceMetric: 0.8147\n",
            "Epoch 18/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0119 - accuracy: 0.9886 - DiceMetric: 0.8053 - val_loss: 0.0133 - val_accuracy: 0.9875 - val_DiceMetric: 0.8164\n",
            "Epoch 19/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0117 - accuracy: 0.9886 - DiceMetric: 0.8042 - val_loss: 0.0151 - val_accuracy: 0.9876 - val_DiceMetric: 0.7920\n",
            "Epoch 20/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0121 - accuracy: 0.9885 - DiceMetric: 0.7921 - val_loss: 0.0130 - val_accuracy: 0.9875 - val_DiceMetric: 0.8178\n",
            "Epoch 21/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0116 - accuracy: 0.9886 - DiceMetric: 0.8042 - val_loss: 0.0125 - val_accuracy: 0.9874 - val_DiceMetric: 0.8289\n",
            "Epoch 22/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0115 - accuracy: 0.9886 - DiceMetric: 0.8063 - val_loss: 0.0135 - val_accuracy: 0.9873 - val_DiceMetric: 0.7958\n",
            "Epoch 23/25\n",
            "124/124 [==============================] - 22s 178ms/step - loss: 0.0112 - accuracy: 0.9887 - DiceMetric: 0.8141 - val_loss: 0.0136 - val_accuracy: 0.9875 - val_DiceMetric: 0.8123\n",
            "Epoch 24/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0111 - accuracy: 0.9886 - DiceMetric: 0.8160 - val_loss: 0.0153 - val_accuracy: 0.9872 - val_DiceMetric: 0.7896\n",
            "Epoch 25/25\n",
            "124/124 [==============================] - 22s 179ms/step - loss: 0.0112 - accuracy: 0.9887 - DiceMetric: 0.8191 - val_loss: 0.0125 - val_accuracy: 0.9877 - val_DiceMetric: 0.8174\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6aa02c02d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0yz227RzmyI",
        "outputId": "22756fd2-f2bb-4089-d046-938996561c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.013260588981211185; accuracy of 98.9195168018341%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "jFP-3gQ9BO8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P0-RG0wjzA6"
      },
      "outputs": [],
      "source": [
        "Ypred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "J1ra2EoVycvl",
        "outputId": "a2b44f0f-e16c-4a48-d668-6deb3e7d7589"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfNUlEQVR4nO3da3Bb6X3f8e8fAAFeQBIC7yIliqKo6C6tVnuXMl7baWTXs+t67MymmkZundlpJ804ccfJbv2i7bumzaRxZly7mviy9tjruIrrXXvcajeb9XVWWl1irlYUJVIixYtI8QoSBAkQl6cvcA4W0lIriSBAkOf/meEQOLich4c4PzznOc95HjHGoJRyLtdqF0Aptbo0BJRyOA0BpRxOQ0Aph9MQUMrhNASUcri8hYCIHBWRKyLSKyIv5Gs9SqncSD76CYiIG7gK/A4wBJwFft8Y07XiK1NK5cSTp/d9FOg1xlwHEJHvA88CS4aAiGiPJaXyb8IYU3fnwnwdDjQDg1n3h6xlGSLyvIicE5FzeSqDUup2N5ZamK+awD0ZY04AJ0BrAkqtpnzVBIaBTVn3W6xlSqkik68QOAt0iEibiHiB54BX87QupVQO8nI4YIxJiMi/B04BbuAbxphL+ViXUio3eTlF+MCF0DYBpQrhvDHm0J0LtcegUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg637BAQkU0i8qaIdInIJRH5vLU8KCKvi0iP9XvDyhVXKbXScqkJJID/YIzZBTwO/JGI7AJeAN4wxnQAb1j3lVJFatkhYIwZMcZcsG6HgctAM/As8JL1tJeAT+ZaSKVU/qzIrMQisgV4CDgDNBhjRqyHRoGGu7zmeeD5lVi/Umr5cm4YFBE/8PfAnxhjZrMfM+kpj5eccdgYc8IYc2ipWVKVUoWTUwiISAnpAPiuMeaH1uJbItJkPd4EjOVWRKVUPuVydkCArwOXjTF/lfXQq8Bx6/Zx4JXlF08plW+SrrEv44Uih4FfAheBlLX4P5JuF/gBsBm4AfyeMWbqHu+1vEIopR7E+aUOv5cdAitJQ0CpglgyBLTHoFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOtxKzErtF5J9E5CfW/TYROSMivSLydyLizb2YSql8WYmawOeBy1n3/wL4H8aYbcA08LkVWIdSKk9ynZq8BfjnwN9a9wX4MHDSespLwCdzWYdSKr9yrQn8NfBnvDcrcQ0QMsYkrPtDQPNSLxSR50XknIicy7EMSqkcLDsEROQTwJgx5vxyXm+MOWGMObTULKlKqcLx5PDap4BnROTjQClQBXwZCIiIx6oNtADDuRdTKZUvy64JGGNeNMa0GGO2AM8B/2iMOQa8CXzaetpx4JWcS6mUypt89BP4c+ALItJLuo3g63lYh1JqhYgxZrXLgIisfiGUWv/OL9UGpz0GlXI4DQGlHE5DQCmH0xBQyuE0BJRyOA0BpRwulx6DShWMy+XC7XaTvkYN7FPbiUSCYjjNvZZpCKii53a78Xg8VFVVISKICKlUimQyyezsLMlkUoMgBxoCqmjZO/+hQ4dobm5m9+7dlJSU4HK5iMfjzM/Pc/r0aUZGRrh69SqpVOreb6reR0NAFS2Px0NZWRkPPfQQ+/fv5+mnn8bn8+FyuYjFYszNzWGM4dKlS1y7dg1Ag2AZNARU0dq0aRN79+7lmWeeYffu3QSDQVyudFu2MYZ4PM5zzz3H2bNn+c1vfkMoFCIcDq9yqdceDQFVlESEQCDA1q1baWpqora2lpKSksxjxhhKSkpobm5mZGSEhoYG4vF4pnag7p+eIlRFR0TweDy0tbXxoQ99iPr6ekpKSjKNgvZzRITq6mpaWlo4cuQIW7ZswePxZJ6j7o/WBFTRcrvdeL1eXC7Xkju2iOB2u6mtreXw4cMsLi4SjUbp6ekhEomsQonXJg0BVZTsb/p7fbO7XC5qa2v56Ec/SjweZ3FxkZGREQ2BB6CHA6oopVIp4vE44XD4nh2C3G435eXlbN26lUcffZTKykrcbncBS7u2aQioomOMwRhDJBJhcnKSaDT6gUFgHxZUVVVRX1+Pz+fTdoEHoIcDqiglk0m6urp4+eWXqa+vx+1209DQgNvtzpwmzGYHwZ0NiPmUvZ613D9BQ0AVrdnZWQYGBjh79izhcJhdu3ZRVVVFMBikrKwss8NDuvawuLjI/Px8Xq8nEBEqKiqoqKigrq4uE0i9vb1Eo9E1GQYaAqpoTU9PEwqF+Pa3v83GjRs5evQobW1tHDhwgObmZqqrq297fiQSYXx8nHg8nred0e1209jYSGtrK08++SQlJSUkk0m++c1vMjo6yuLiYl7Wm08aAqqoGWOYmJhgfn6eH/3oR9TW1vKLX/yCo0ePsmfPHlpbW/F4PMTjcfr7+zl//jzhcDgvNQGv10t1dTWf+cxn2LZtG/v372dhYYG5uTleeeUVpqenNQSUyoe5uTnm5uYYHx+noqKCK1eu0NjYiN/vzzQELiwsMDo6mqmW5yME3G43ZWVlPPzww3R0dLBz506mp6cZGxujtLQUj2dt7k5rs9RFxu7GqvLLGMP8/DyxWIyXX36ZX/3qV3zxi1+krKyMgYEBfvnLX9LZ2Zm3PgJ2m8PQ0BDl5eXU1dXR2dnJ5cuXGR8fZ2FhIS/rzTcNgWUSEfx+P6WlpVRWVjI5OUk4HF6TDUNrSSqVIpVKMT4+TiKR4Pz58/h8PoaGhhgYGCASieTtf2A3Pvb29rK4uEgikeDdd9+lp6eHubk5EonEvd+kCOnkI8vk9XrZtWsXmzZt4sCBA5w6dYrOzk4WFxe1VlAgLpcr0zgYjUaJx+N53xFdLhd1dXX4fD7Ky8uZmJhgZmZmrYxwtPKTj4hIQEROiki3iFwWkSdEJCgir4tIj/V7Qy7rKFYej4fW1lZ27drFE088QXt7O8FgUHuqFVAqlWJ+fp75+XkWFxdJJpN5X6cxhnA4nGkLiEQiayUA7irXHoNfBv6fMWYHsB+4DLwAvGGM6QDesO6vOx6Ph5aWFjo6OnjkkUfYsmWLhsAqiMVixGKxgg0xZrdLhMNhpqamWFhYWNMBADmEgIhUA7+NNeGoMWbRGBMCngVesp72EvDJXAtZjOLxONevX2dsbAyv10t9fT2bN2/OXPOu1h+7V2J5eTmlpaVL9lxci3JpGGwDxoFvish+4DzweaDBGDNiPWcUaFjqxSLyPPB8DutfValUiunpaWZmZojFYgQCAVpbW7lw4QKxWIx4PL7aRVQrwOVy4fF48Hq9+P1+fD4flZWVRKNRbt26lWmLWMtyCQEPcBD4Y2PMGRH5MndU/Y0x5m6NfsaYE8AJWJsNg4lEgv7+fpqbm+np6WHfvn3s3LmTrq4uent7uXnz5moXUeXI5XJRUVFBfX09bW1tPPbYY2zevJmOjg56enr4zne+w7Vr1xgZGbn3mxWxXEJgCBgyxpyx7p8kHQK3RKTJGDMiIk3AWK6FLEapVIpIJMLIyAgXLlzg4MGDNDY2cuDAAbxeb+YU1lo/XnSq6upqAoFAZqTjrVu30t7eTk1NDX6/n8HBwcx1CmvdskPAGDMqIoMi8lvGmCvAR4Au6+c48F+t36+sSEmLjN1KfOPGDX72s5/R3t7Ovn37ePrpp6mqquL06dMYY9bFh8Rp7NOA7e3tfPazn6W1tZW2tjZ8Ph8Ao6OjuFyuzGXOa12unYX+GPiuiHiB68C/Jt3Y+AMR+RxwA/i9HNdR1OLxODMzMywuLuJyudi/fz8A27Zt4+bNm4yNrcuK0LokItTV1dHY2MixY8fYuXMnBw8epKKiItMQGIvF6O7upqenh8nJSWKx2GoXO2c5hYAx5jfA+zofkK4VOEIikWBubo5oNEoymaSuro6NGzfS2NjI7OyshsAaICK4XC5KS0tpbGykvb2dQ4cOsWPHDhoaGjJjHBpjSCaTmXC3/+drnXYbzlEkEqGvr4/r16/T399Pe3s7dXV1PPXUU0SjUfr6+rRdoMiVlZVRW1vLk08+yZEjR3jqqafYsmULFRUVtw1ymkgkmJ+f56233uLdd99dN4d6GgI5SiaTzM/Pc+PGDS5dusTGjRsz4+EHAgFKSkqIx+MaBEXCHg3IviKwtLSUjo4ONm7cyBNPPMHOnTtpamqirKzstglQIR0CCwsLjI2NMT09vYp/xcrSEMhRIpEgHA7z1ltvMT09zcGDB6murmbXrl2cP3+e8vLyNX1xyXpi7/wej4fS0lJaWlpoamri2LFjtLe38/DDD1NSUpLp9ZkdAHZPwVAoRF9fH6Ojo6v1Z6w4DYEVMjo6iohw9epVtmzZQnNzM48++ijhcJg333yTsbGxddGIVCyqqqooLS297YrBhYUFFhYW8Pl8lJSU4Pf78Xq9+Hw+ampqqKysZNOmTfj9foLBII2NjQSDQXbt2pWptd1tjgOAiYkJBgcHCYfD6+KsgE1DYIWEQiGSySSDg4NUV1fT0dHBjh07WFhYoLu7m/n5+cxhgR4a5MaeoiwQCNwWAlNTU0A6IMrKyggGg/j9fvx+P5s2baK2tpZ9+/axYcMGGhoaqK2txe/3U1ZW9oE7v216eppbt24RiUTW5AhCd6MhsELsMfJ/+tOfcuvWLfbv309HRwebN28mGAzS3d3Nt771rcy4eRoEy+Pz+fD7/Rw7dowjR45QXl6euc7/2rVrDAwMcPDgQYLBIMFgkJKSEnw+X6Z2UFZWhsfjwePx4Ha7M8f9HxQA9hgGly5d4vTp00QikXVxVsCmIbBC7NNHQ0NDNDQ0MDMzkxkZd/v27ZSUlLB//34GBwfp6+sjHA6vq2+TQvH5fNTV1bFlyxa2b99OeXk5kB71p6ysjJqaGnbv3k1VVRVVVVWZHd7lct32bf8gQ5KnUikWFxcZHx9neHh43fUE1RBYQclkkqtXr+LxeOjs7GTHjh20t7ezZ88e2tvbaW9v58yZM7z66qucO3duzfc5Xw3BYJBDhw6xfft2WlpaMsOOG2NoaWkhlUpldvbl7PBLWVxcZGZmht7eXi5fvrzuwltDYIUtLi4yPT3N22+/TXl5OZs3b8bj8eDz+WhoaKCxsZGmpqZMF9QP4nK5tA0hS0lJSea4vqamJjNPof1jjLmvY/sHYYwhFArR29vLrVu3mJmZWXf/j/VxQXQRSSQSTE1Ncfr0afr7+4nFYqRSKTweD7W1tZkgsKuxS7F7sGUfu2Z/2As1w04xERG8Xi91dXWZxr07d/iV3i52AIdCIbq7uxkdHV2X40hqTSAPIpEIFy9eZPPmzQQCAQ4fPkxNTU1mx7Znz/F4PCSTycz560AgQGVlJa2trdTU1LBjxw7C4TChUIgbN24wNzeXaaSC9BmJSCTC7OzsbSPrZM/mm0gkMufGg8EgXq+X2dnZzDTeyWQy857F+g1nz/pz5MgRDh8+zL59+6iurs57EKZSKebm5uju7ubHP/4xw8PD66pB0KYhkAfxeJzp6WkGBgbo6upiz549VFZWZlqpg8Eg9fX1mavQPB4Pfr+f2tpaampq6OjooL6+nj179jAzM8PU1BSBQOC2nd2elGN2dpaJiYnM6Ld2raG0tBRID8Dp9Xoz/eJ9Ph/T09NEo1Hm5uYyg3PaE2cU4/lvn89HVVUVO3bsoK2tjUAggNfrzes67StAp6amGB0d5fr160QikaINylxoCOSBMYZYLMbZs2fp6+tjx44dmYFJ7bEI6+rquHHjBkNDQwQCAQ4cOEBTUxM1NTVUV1dTUlJCSUkJxpjMNN3Z39Z2NTUSiTA8PEwkEmF6epqysjLKysoIBAJAuoNLRUUFgUAg0xZhB4A9s8/s7CwnT56kv7+fd955p6g+6CJCe3s7HR0dHD9+nMbGRkpLS/NaC7C3eTgc5o033uCtt97i+vXr665B0KYhkEfRaJSpqSkuXLiAMYba2trMt/62bdvYsGEDmzdvpqKigtbWVqqrqzNzGdintCD9ofT5fLcFAKQHO7V7zsViMSKRCF6vF6/Xmzl/Xltbi8/no6Kigqqqqsy1DFVVVVRWVmbCo5jGRrQPZ0pLSykrK+Ohhx5i9+7d1NXVUVFRkff1G2OYmppiaGiICxcu0N/fv66v/9AQyKNoNMri4iKnTp1ieHiYxx57jA0bNuD3+9m9ezeQPu60GwJh6dNZSy0zxlBVVQVAbW3tA5WrrKwMgLq6OsLhMJWVlQBFc/7b5XJlevw1NDTwsY99jAMHDmSmKM8n+1BrcHCQrq4uXnvtNSYmJtZlW4BNQyDPUqkUN27cIJlM8tprr7F7924eeeSRTMv2Uher3I9cq8N2lffSpUtcunSJy5cvMzw8nNN75kpEaG5upqWlhWeeeYa6urpM24jdsGq7M6zu1bB551mV7CnNbclkkomJCcbGxvje975HV1dXZtyA9UxDoACmp6dxu91cvHgRv9/P3r17KS0tfd+lqoWUSqVIJBIMDQ3R1dXFrVu3mJ2dXZWy2ESE6upqmpubOXz4MHV1ddTU1GS6+tqj+mbP/Wg34NmTj9zt9J19daD9O7tGkUgkSCQSxGIxbt68mZnduLu7m7m5uaKoHeWThkABpFIppqamOHnyJJOTk9TU1LB3717q6+uB3L/VlyMSiTA6OsrPf/5zTp06xezsbNGc/04kEoRCIWKxGOPj43fdPsYYIpEIExMTdHZ2EgqFCIfDtz3Hfm1LS0vmwq6Ghga2bduWaXDt7+9nbGyM8+fP09vbS29vLwMDA8zPz6/7AAANgYJJJpOZ8/3nzp2juroaj8dDIBAoeI3AvjZ+aGiIsbExpqamimK8A3vw1lu3bnH27NlMX4q7PTeVShGNRgmFQly9epVwOMz8/Pz7nisiTE5O4vf7mZiYoLa2lqGhoUxtaHBwkMnJSS5fvszNmzcZGRlhYWFhXbcDZNMQKBB7x+vs7GRoaAi32000GuXgwYOZQwPIf60gu4+BfQozFAoVRS3AGMPAwACDg4NcuHABuPv2yD4cuN9Rne2zDvZEInYnKXs+wWIIwtWgIVBg9mnD1157jZ6eHgYGBmhsbMx0gvH7/ZnBLfIhmUwyNjZGT08Pv/71rxkbGyuKAMj2oEO132+V3b7S0+7KbS+z+2A4lYZAgcXjceLxOGfOnKG7u5tkMsnWrVtJpVJs3rwZEcHv9+N2u1f0Yhj7GzMejzMyMkJfXx+dnZ1MTk6uyPuvtHztlPa3v1O/9ZcixdDwsRanIcuVy+XC7XZTVVVFeXl5ptGqtbWVT33qU2zcuJHm5ubMBUSwvEMFe+c3xjA+Ps7IyAhf+cpXuHLlCm+//TaJRMLR34IOc94Y874pArQmsErsb6TJyUlCoVCm/38oFGLr1q1MTk6ysLBARUVFZggsu6Es+9JZuH1Hzx4j3x5xZ2FhgUgkwvXr1xkcHKS7u5vh4eF12w1WPRitCRQRu+fghg0bCAQC7N27l+3bt7Nz50727t1LTU0NNTU1mUMF+38Xi8VIJpPE4/HMRUr2se/w8DC9vb1cvHiRN998kxs3bqzL0XHUfVn5moCI/Cnwh4ABLpKehqwJ+D5QQ3q68n9ljNGvnPtgN1zZQ5RfvnyZyclJ+vr6uHTpUuYiIDsE4L2JUePxONFolMrKSsrLyzNj5A8PDzM6OsrQ0BD9/f2EQiENAHWbZdcERKQZ+BWwyxizICI/AH4KfBz4oTHm+yLyNaDTGPPVe7yXfiLvwq4dVFdX3zZSkdvtvm3Qi1gsxtzcHMFgkKqqKuLxOAsLCwwODhKNRolGo7rjq7y0CXiAMhGJA+XACPBh4F9aj78E/GfgA0NA3Z3dKWZ2dpZIJEI4HH7f6UP7FJfdIcnj8WRqFdFotKgHDFGrL5epyYdF5C+BAWABeI109T9kjLHPvwwBzUu9XkSeB55f7vqdxD5vbvdv/yA6wYl6UMvukSIiG4BngTZgI1ABHL3f1xtjThhjDi1VPVFKFU4u3dI+CvQZY8aNMXHgh8BTQEBE7BpGC7C616cqpT5QLiEwADwuIuWS7sXyEaALeBP4tPWc48AruRVRKZVPyw4BY8wZ4CRwgfTpQRdwAvhz4Asi0kv6NOHXV6CcSqk80c5CSjnHkqcIdfIRpRxOQ0Aph9MQUMrhNASUcjgNAaUcTkNAKYfTEFDK4TQElHI4DQGlHE5DQCmH0xBQyuE0BJRyOA0BpRxOQ0Aph9MQUMrhNASUcjgNAaUcTkNAKYfTEFDK4TQElHI4DQGlHE5DQCmH0xBQyuE0BJRyOA0BpRzuniEgIt8QkTEReTdrWVBEXheRHuv3Bmu5iMjfiEiviLwjIgfzWXilVO7upybwLd4/5fgLwBvGmA7gDes+wMeADuvneeCrK1NMpVS+3DMEjDG/AKbuWPws8JJ1+yXgk1nLv23STpOeprxppQqrlFp5y20TaDDGjFi3R4EG63YzMJj1vCFr2fuIyPMick5Ezi2zDEqpFeDJ9Q2MMWY5swobY06QnspcZyVWahUttyZwy67mW7/HrOXDwKas57VYy5RSRWq5IfAqcNy6fRx4JWv5H1hnCR4HZrIOG5RSxcgY84E/wMvACBAnfYz/OaCG9FmBHuAfgKD1XAG+AlwDLgKH7vX+1uuM/uiP/uT959xS+59YO+Gq0jYBpQrivDHm0J0LtcegUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6nIaCUw2kIKOVwGgJKOZyGgFIOpyGglMNpCCjlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg53zxAQkW+IyJiIvJu17L+LSLeIvCMi/0dEAlmPvSgivSJyRUR+N18FV0qtjPupCXwLOHrHsteBPcaYfcBV4EUAEdkFPAfstl7zP0XEvWKlVUqtuHuGgDHmF8DUHcteM8YkrLunSU9BDvAs8H1jTMwY0wf0Ao+uYHmVUitsJdoE/g3wf63bzcBg1mND1rL3EZHnReSciJxbgTIopZbJk8uLReRLQAL47oO+1hhzAjhhvY/OSqzUKll2CIjIZ4FPAB8x781vPgxsynpai7VMKVWklnU4ICJHgT8DnjHGzGc99CrwnIj4RKQN6ADezr2YSql8uWdNQEReBj4E1IrIEPCfSJ8N8AGviwjAaWPMvzXGXBKRHwBdpA8T/sgYk8xX4ZVSuZP3avKrWAhtE1CqEM4bYw7duVB7DCrlcBoCSjmchoBSDqchoJTDaQgo5XAaAko5nIaAUg6X07UDK2gCiFi/V1stWo5sWo7breVytC61sCg6CwGIyLmlOjJoObQcWo78lkMPB5RyOA0BpRyumELgxGoXwKLluJ2W43brrhxF0yaglFodxVQTUEqtAg0BpRyuKEJARI5a8xT0isgLBVrnJhF5U0S6ROSSiHzeWh4UkddFpMf6vaFA5XGLyD+JyE+s+20icsbaJn8nIt4ClCEgIietOSUui8gTq7E9RORPrf/JuyLysoiUFmp73GWejSW3gaT9jVWmd0TkYJ7LkZ/5Powxq/oDuIFrwFbAC3QCuwqw3ibgoHW7kvT8CbuA/wa8YC1/AfiLAm2HLwDfA35i3f8B8Jx1+2vAvytAGV4C/tC67QUChd4epEen7gPKsrbDZwu1PYDfBg4C72YtW3IbAB8nPdK2AI8DZ/Jcjn8GeKzbf5FVjl3WfuMD2qz9yX3f68r3B+s+/tgngFNZ918EXlyFcrwC/A5wBWiyljUBVwqw7hbgDeDDwE+sD9VE1j/8tm2UpzJUWzuf3LG8oNuD94atD5Lu0foT4HcLuT2ALXfsfEtuA+B/Ab+/1PPyUY47HvsXwHet27ftM8Ap4In7XU8xHA7c91wF+SIiW4CHgDNAgzFmxHpoFGgoQBH+mvTArSnrfg0QMu9N8FKIbdIGjAPftA5L/lZEKijw9jDGDAN/CQwAI8AMcJ7Cb49sd9sGq/nZXdZ8H0sphhBYVSLiB/4e+BNjzGz2YyYdq3k9hyoinwDGjDHn87me++AhXf38qjHmIdLXctzWPlOg7bGB9ExWbcBGoIL3T4O3agqxDe4ll/k+llIMIbBqcxWISAnpAPiuMeaH1uJbItJkPd4EjOW5GE8Bz4hIP/B90ocEXwYCImJf4FWIbTIEDBljzlj3T5IOhUJvj48CfcaYcWNMHPgh6W1U6O2R7W7boOCf3az5Po5ZgZRzOYohBM4CHVbrr5f0hKav5nulkh4r/evAZWPMX2U99Cpw3Lp9nHRbQd4YY140xrQYY7aQ/tv/0RhzDHgT+HQByzEKDIrIb1mLPkJ66PiCbg/ShwGPi0i59T+yy1HQ7XGHu22DV4E/sM4SPA7MZB02rLi8zfeRz0aeB2gA+Tjp1vlrwJcKtM7DpKt17wC/sX4+Tvp4/A2gB/gHIFjA7fAh3js7sNX6R/YC/xvwFWD9B4Bz1jb5EbBhNbYH8F+AbuBd4DukW70Lsj2Al0m3RcRJ144+d7dtQLoB9yvW5/YicCjP5eglfexvf16/lvX8L1nluAJ87EHWpd2GlXK4YjgcUEqtIg0BpRxOQ0Aph9MQUMrhNASUcjgNAaUcTkNAKYf7/195xLC6VxOcAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(np.reshape(Ypred[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()\n",
        "plt.imshow(np.reshape(Y_test[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikB_eI_ZmVtq"
      },
      "outputs": [],
      "source": [
        "def dice(true_mask, pred_mask, non_seg_score=1.0):\n",
        "    \"\"\"\n",
        "        Computes the Dice coefficient.\n",
        "        Args:\n",
        "            true_mask : Array of arbitrary shape.\n",
        "            pred_mask : Array with the same shape than true_mask.  \n",
        "        \n",
        "        Returns:\n",
        "            A scalar representing the Dice coefficient between the two segmentations. \n",
        "        \n",
        "    \"\"\"\n",
        "    assert true_mask.shape == pred_mask.shape\n",
        "\n",
        "    true_mask = np.asarray(true_mask).astype(bool)\n",
        "    pred_mask = np.asarray(pred_mask).astype(bool)\n",
        "\n",
        "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
        "    im_sum = true_mask.sum() + pred_mask.sum()\n",
        "    if im_sum == 0:\n",
        "        return non_seg_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2. * intersection.sum() / im_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBVFzRQmXI-",
        "outputId": "07cfdf0b-9569-4330-c032-a2f125b48e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07394345500499618"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "diceaux=dice(Y_test[160],Ypred[160])\n",
        "diceaux"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fit Kfold"
      ],
      "metadata": {
        "id": "lc2Sj8PPuJBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Fh7g3mmhuNPV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ],
      "metadata": {
        "id": "kj7ESdJAuOaW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 epochs"
      ],
      "metadata": {
        "id": "MMoOw7t4c3Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7gaF3LTvOU-",
        "outputId": "52a85544-6d46-4a94-a4a7-afe8b762cbbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.014021586626768112; accuracy of 98.92089366912842% DiceMetric of 83.75591039657593%\n",
            "Score for fold 2: loss of 0.019117744639515877; accuracy of 98.81448745727539% DiceMetric of 84.43223834037781%\n",
            "Score for fold 3: loss of 0.01881265453994274; accuracy of 98.86800646781921% DiceMetric of 81.77867531776428%\n",
            "Score for fold 4: loss of 0.016339754685759544; accuracy of 98.87001514434814% DiceMetric of 83.96406173706055%\n",
            "Score for fold 5: loss of 0.01778031513094902; accuracy of 98.91332983970642% DiceMetric of 83.52100849151611%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 epochs"
      ],
      "metadata": {
        "id": "1xW8vkk3c0rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljMT8Ak4cz6R",
        "outputId": "59e52835-111e-4537-8d7a-9673ba0017b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.020024169236421585; accuracy of 98.9259123802185% DiceMetric of 83.23488235473633%\n",
            "Score for fold 2: loss of 0.027436159551143646; accuracy of 98.80136251449585% DiceMetric of 78.62027883529663%\n",
            "Score for fold 3: loss of 0.027285216376185417; accuracy of 98.84647130966187% DiceMetric of 76.36862397193909%\n",
            "Score for fold 4: loss of 0.02436514012515545; accuracy of 98.84511828422546% DiceMetric of 74.79293942451477%\n",
            "Score for fold 5: loss of 0.02152051404118538; accuracy of 98.88449311256409% DiceMetric of 80.96136450767517%\n"
          ]
        }
      ]
    }
  ]
}