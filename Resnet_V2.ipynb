{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet V2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbXNG9UJbv6wraFsh2/BgN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeSotoG/U-Net-ResNetBlocks/blob/main/Resnet_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcH2AvTh97gF"
      },
      "source": [
        "##Descarga datos\n",
        "Los datos se encuentran en el drive, por lo que usara gdown para sacarlos directamente y no tener que hacer la coneccion, ya que estamos descargando un zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7GLXIiagwH3",
        "outputId": "019a1fab-3e83-4c77-c266-a570d3da393a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt\n",
            "To: /content/input.zip\n",
            "100% 597M/597M [00:03<00:00, 188MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uq8I6BfRhogZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H9Y2Q3Bce47L"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_jqAPlaMKtpg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hmJoArAEd41C"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  X[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)\n",
        "mas=\"/masks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  Y[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Borrar directorio /input en caso de error"
      ],
      "metadata": {
        "id": "3NcX5DC3VvAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/input"
      ],
      "metadata": {
        "id": "HM4Ry8Dg0ibG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6IAoTKTuO5B"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ub5XKwbdAQ32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.3, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resnet"
      ],
      "metadata": {
        "id": "P6CambWxdEwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6 \n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ],
      "metadata": {
        "id": "Urgfb0zMWlz-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kYTxYQ7sOH-O"
      },
      "outputs": [],
      "source": [
        "def conv_e_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([s,c])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return (c,s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KkWwK5tJPOhT"
      },
      "outputs": [],
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (1, 1), activation='relu', kernel_initializer='he_normal', padding='same')(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (3, 3), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[2], (1, 1), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([s,c])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujtVvPhdOIr3",
        "outputId": "ba4ac2e8-3370-4167-903f-8dd6c8cdeb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 128, 128, 1)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 128, 128, 8)  16          ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128, 128, 8)  32         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 128, 128, 8)  0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 128, 128, 8)  584         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128, 128, 8)  32         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128, 128, 8)  0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 16  32          ['lambda[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 16  144         ['dropout_1[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 16  64         ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 16  64         ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 128, 128, 16  0           ['batch_normalization_3[0][0]',  \n",
            "                                )                                 'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                   (None, 128, 128, 16  0           ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 128, 128, 16  272         ['re_lu[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128, 128, 16  64         ['conv2d_4[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128, 128, 16  0           ['batch_normalization_4[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 128, 128, 16  2320        ['dropout_2[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 128, 128, 16  64         ['conv2d_5[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 128, 128, 16  0           ['batch_normalization_5[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 32  544         ['re_lu[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 32  544         ['dropout_3[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 32  128        ['conv2d_7[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 32  128        ['conv2d_6[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 128, 128, 32  0           ['batch_normalization_7[0][0]',  \n",
            "                                )                                 'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)                 (None, 128, 128, 32  0           ['add_1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 128, 32  1056        ['re_lu_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 32  128        ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128, 128, 32  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 128, 128, 32  9248        ['dropout_4[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 128, 128, 32  128        ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 128, 128, 32  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 128, 128, 64  2112        ['re_lu_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 128, 64  2112        ['dropout_5[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 128, 128, 64  256        ['conv2d_11[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128, 128, 64  256        ['conv2d_10[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_11[0][0]', \n",
            "                                )                                 'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)                 (None, 128, 128, 64  0           ['add_2[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 128, 128, 64  4160        ['re_lu_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 128, 128, 64  256        ['conv2d_12[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 128, 128, 64  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 128, 128, 64  36928       ['dropout_6[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128, 128, 64  256        ['conv2d_13[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 128, 128, 64  0           ['batch_normalization_13[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  8320        ['re_lu_2[0][0]']                \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  8320        ['dropout_7[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 128, 128, 12  0           ['batch_normalization_15[0][0]', \n",
            "                                8)                                'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)                 (None, 128, 128, 12  0           ['add_3[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 128)  0          ['re_lu_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 64, 128)  16512       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 64, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 64, 64, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 64, 64, 128)  147584      ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 64, 128)  512        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 64, 64, 128)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 64, 64, 256)  33024       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 64, 256)  33024       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 64, 64, 256)  0           ['batch_normalization_19[0][0]', \n",
            "                                                                  'batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)                 (None, 64, 64, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 128, 128, 25  262400     ['re_lu_4[0][0]']                \n",
            " ose)                           6)                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 128, 128, 38  0           ['conv2d_transpose[0][0]',       \n",
            "                                4)                                'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 128, 128, 64  24640       ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 128, 128, 64  256        ['conv2d_20[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_20[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 128, 128, 64  36928       ['dropout_10[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 128, 128, 64  256        ['conv2d_21[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 128, 128, 64  0           ['batch_normalization_21[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 128, 128, 12  49280       ['concatenate[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 128, 128, 12  8320        ['dropout_11[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 128, 128, 12  512        ['conv2d_23[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 128, 128, 12  512        ['conv2d_22[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 128, 128, 12  0           ['batch_normalization_23[0][0]', \n",
            "                                8)                                'batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)                 (None, 128, 128, 12  0           ['add_5[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 12  65664      ['re_lu_5[0][0]']                \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 128, 128, 32  6176        ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 128, 128, 32  128        ['conv2d_24[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_24[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 128, 128, 32  9248        ['dropout_12[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 128, 128, 32  128        ['conv2d_25[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 128, 128, 32  0           ['batch_normalization_25[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 128, 128, 64  12352       ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 128, 128, 64  2112        ['dropout_13[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 128, 128, 64  256        ['conv2d_27[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 128, 64  256        ['conv2d_26[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 128, 128, 64  0           ['batch_normalization_27[0][0]', \n",
            "                                )                                 'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)                 (None, 128, 128, 64  0           ['add_6[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 64  16448      ['re_lu_6[0][0]']                \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 96  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                )                                 'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 128, 128, 16  1552        ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 128, 16  64         ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_28[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 128, 128, 16  2320        ['dropout_14[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128, 128, 16  64         ['conv2d_29[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_29[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 128, 128, 32  3104        ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 128, 32  544         ['dropout_15[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 128, 128, 32  128        ['conv2d_31[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 128, 128, 32  128        ['conv2d_30[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 128, 128, 32  0           ['batch_normalization_31[0][0]', \n",
            "                                )                                 'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)                 (None, 128, 128, 32  0           ['add_7[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 32  4128       ['re_lu_7[0][0]']                \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 128, 128, 48  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                )                                 'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 128, 128, 8)  392         ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 128, 128, 8)  32         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 128, 128, 8)  584         ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 128, 128, 8)  32         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 128, 128, 8)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 128, 128, 16  784         ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 128, 128, 16  144         ['dropout_17[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 128, 128, 16  64         ['conv2d_35[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 128, 128, 16  64         ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 128, 128, 16  0           ['batch_normalization_35[0][0]', \n",
            "                                )                                 'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)                 (None, 128, 128, 16  0           ['add_8[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 128, 128, 1)  17          ['re_lu_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 822,825\n",
            "Trainable params: 818,409\n",
            "Non-trainable params: 4,416\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "#Contraction path\n",
        "c1,z1 = conv_e_block(s,[8,8,16])\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "c2,z2 = conv_e_block(c1,[16,16,32])\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        " \n",
        "c3,z3 = conv_e_block(c2,[32,32,64],0.2)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4,z4 = conv_e_block(c3,[64,64,128],0.2)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5 = conv_block(p4,[128,128,256],0.3)\n",
        "\n",
        "\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, z4])\n",
        "c6 = conv_block(u6,[64,64,128],0.2)\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(1, 1), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, z3])\n",
        "c7 = conv_block(u7,[32,32,64],0.2)\n",
        "\n",
        "\n",
        "u8 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(1, 1), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, z2])\n",
        "c8 = conv_block(u8,[16,16,32])\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(1, 1), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, z1], axis=3)\n",
        "c9 = conv_block(u9,[8,8,16])\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Fit"
      ],
      "metadata": {
        "id": "4JFyLMRezeWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,batch_size=16,epochs=25,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCB8atJ1zda4",
        "outputId": "51497dfb-23aa-4327-b30b-2391fdac7b8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "124/124 [==============================] - 52s 280ms/step - loss: 0.0566 - accuracy: 0.9849 - DiceMetric: 0.3238 - val_loss: 0.0730 - val_accuracy: 0.9855 - val_DiceMetric: 0.0229\n",
            "Epoch 2/25\n",
            "124/124 [==============================] - 32s 255ms/step - loss: 0.0228 - accuracy: 0.9875 - DiceMetric: 0.6342 - val_loss: 0.0323 - val_accuracy: 0.9830 - val_DiceMetric: 0.5108\n",
            "Epoch 3/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0194 - accuracy: 0.9876 - DiceMetric: 0.6572 - val_loss: 0.0233 - val_accuracy: 0.9847 - val_DiceMetric: 0.6575\n",
            "Epoch 4/25\n",
            "124/124 [==============================] - 31s 252ms/step - loss: 0.0160 - accuracy: 0.9880 - DiceMetric: 0.7156 - val_loss: 0.0199 - val_accuracy: 0.9857 - val_DiceMetric: 0.7339\n",
            "Epoch 5/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0146 - accuracy: 0.9882 - DiceMetric: 0.7458 - val_loss: 0.0191 - val_accuracy: 0.9871 - val_DiceMetric: 0.7156\n",
            "Epoch 6/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0136 - accuracy: 0.9883 - DiceMetric: 0.7689 - val_loss: 0.0134 - val_accuracy: 0.9872 - val_DiceMetric: 0.8039\n",
            "Epoch 7/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0126 - accuracy: 0.9885 - DiceMetric: 0.7873 - val_loss: 0.0152 - val_accuracy: 0.9871 - val_DiceMetric: 0.7590\n",
            "Epoch 8/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0120 - accuracy: 0.9886 - DiceMetric: 0.7952 - val_loss: 0.0130 - val_accuracy: 0.9874 - val_DiceMetric: 0.8204\n",
            "Epoch 9/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0117 - accuracy: 0.9886 - DiceMetric: 0.8028 - val_loss: 0.0139 - val_accuracy: 0.9873 - val_DiceMetric: 0.8008\n",
            "Epoch 10/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0115 - accuracy: 0.9886 - DiceMetric: 0.8014 - val_loss: 0.0133 - val_accuracy: 0.9877 - val_DiceMetric: 0.8161\n",
            "Epoch 11/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0112 - accuracy: 0.9887 - DiceMetric: 0.8089 - val_loss: 0.0134 - val_accuracy: 0.9876 - val_DiceMetric: 0.8221\n",
            "Epoch 12/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0106 - accuracy: 0.9888 - DiceMetric: 0.8220 - val_loss: 0.0134 - val_accuracy: 0.9877 - val_DiceMetric: 0.8120\n",
            "Epoch 13/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0105 - accuracy: 0.9888 - DiceMetric: 0.8272 - val_loss: 0.0122 - val_accuracy: 0.9875 - val_DiceMetric: 0.8352\n",
            "Epoch 14/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0103 - accuracy: 0.9888 - DiceMetric: 0.8327 - val_loss: 0.0127 - val_accuracy: 0.9876 - val_DiceMetric: 0.8289\n",
            "Epoch 15/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0106 - accuracy: 0.9887 - DiceMetric: 0.8261 - val_loss: 0.0127 - val_accuracy: 0.9878 - val_DiceMetric: 0.8260\n",
            "Epoch 16/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0100 - accuracy: 0.9888 - DiceMetric: 0.8377 - val_loss: 0.0116 - val_accuracy: 0.9877 - val_DiceMetric: 0.8550\n",
            "Epoch 17/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0095 - accuracy: 0.9890 - DiceMetric: 0.8491 - val_loss: 0.0116 - val_accuracy: 0.9877 - val_DiceMetric: 0.8386\n",
            "Epoch 18/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0098 - accuracy: 0.9889 - DiceMetric: 0.8385 - val_loss: 0.0137 - val_accuracy: 0.9878 - val_DiceMetric: 0.8147\n",
            "Epoch 19/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0095 - accuracy: 0.9889 - DiceMetric: 0.8506 - val_loss: 0.0114 - val_accuracy: 0.9877 - val_DiceMetric: 0.8458\n",
            "Epoch 20/25\n",
            "124/124 [==============================] - 32s 256ms/step - loss: 0.0091 - accuracy: 0.9890 - DiceMetric: 0.8655 - val_loss: 0.0131 - val_accuracy: 0.9878 - val_DiceMetric: 0.8216\n",
            "Epoch 21/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0095 - accuracy: 0.9889 - DiceMetric: 0.8518 - val_loss: 0.0125 - val_accuracy: 0.9878 - val_DiceMetric: 0.8365\n",
            "Epoch 22/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0089 - accuracy: 0.9890 - DiceMetric: 0.8611 - val_loss: 0.0128 - val_accuracy: 0.9878 - val_DiceMetric: 0.8028\n",
            "Epoch 23/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0086 - accuracy: 0.9891 - DiceMetric: 0.8716 - val_loss: 0.0117 - val_accuracy: 0.9878 - val_DiceMetric: 0.8589\n",
            "Epoch 24/25\n",
            "124/124 [==============================] - 31s 250ms/step - loss: 0.0088 - accuracy: 0.9890 - DiceMetric: 0.8662 - val_loss: 0.0138 - val_accuracy: 0.9878 - val_DiceMetric: 0.8143\n",
            "Epoch 25/25\n",
            "124/124 [==============================] - 31s 251ms/step - loss: 0.0085 - accuracy: 0.9891 - DiceMetric: 0.8771 - val_loss: 0.0120 - val_accuracy: 0.9879 - val_DiceMetric: 0.8354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd13ff600d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0yz227RzmyI",
        "outputId": "99f87ce3-4cff-4606-e08b-51452a7598ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.0090620256960392; accuracy of 98.93296957015991%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "jFP-3gQ9BO8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P0-RG0wjzA6"
      },
      "outputs": [],
      "source": [
        "Ypred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "J1ra2EoVycvl",
        "outputId": "54b71855-7f7d-424b-e934-d2adbefca8c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(np.reshape(Ypred[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()\n",
        "plt.imshow(np.reshape(Y_test[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikB_eI_ZmVtq"
      },
      "outputs": [],
      "source": [
        "def dice(true_mask, pred_mask, non_seg_score=1.0):\n",
        "    \"\"\"\n",
        "        Computes the Dice coefficient.\n",
        "        Args:\n",
        "            true_mask : Array of arbitrary shape.\n",
        "            pred_mask : Array with the same shape than true_mask.  \n",
        "        \n",
        "        Returns:\n",
        "            A scalar representing the Dice coefficient between the two segmentations. \n",
        "        \n",
        "    \"\"\"\n",
        "    assert true_mask.shape == pred_mask.shape\n",
        "\n",
        "    true_mask = np.asarray(true_mask).astype(bool)\n",
        "    pred_mask = np.asarray(pred_mask).astype(bool)\n",
        "\n",
        "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
        "    im_sum = true_mask.sum() + pred_mask.sum()\n",
        "    if im_sum == 0:\n",
        "        return non_seg_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2. * intersection.sum() / im_sum"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred[Ypred>=0.5]=1\n",
        "Ypred[Ypred<0.5]=0"
      ],
      "metadata": {
        "id": "HYMrfFWTr36p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBVFzRQmXI-",
        "outputId": "62ec1532-61eb-4334-8da9-573aa87d178b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7880539499036608"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "diceaux=dice(Y_test[160],Ypred[160])\n",
        "diceaux"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fit Kfold"
      ],
      "metadata": {
        "id": "lc2Sj8PPuJBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Fh7g3mmhuNPV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ],
      "metadata": {
        "id": "kj7ESdJAuOaW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 epochs"
      ],
      "metadata": {
        "id": "Q-j4BVnxg6rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7gaF3LTvOU-",
        "outputId": "800243e6-cc7a-439c-f310-85f8881ebe7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.0132822310552001; accuracy of 98.94148111343384% DiceMetric of 86.96046471595764%\n",
            "Score for fold 1: loss of 0.013708808459341526; accuracy of 98.8329529762268% DiceMetric of 88.82409930229187%\n",
            "Score for fold 1: loss of 0.01680542342364788; accuracy of 98.87604117393494% DiceMetric of 84.18727517127991%\n",
            "Score for fold 1: loss of 0.014180616475641727; accuracy of 98.88461828231812% DiceMetric of 88.98268342018127%\n",
            "Score for fold 1: loss of 0.016670048236846924; accuracy of 98.9275872707367% DiceMetric of 86.68215274810791%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 epochs"
      ],
      "metadata": {
        "id": "KmpnG4oag89r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUsbIJHmg-wM",
        "outputId": "83eb3998-cda1-4584-bbe7-4f7571ef00df"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.01654903218150139; accuracy of 98.94940853118896% DiceMetric of 90.47139883041382%\n",
            "Score for fold 1: loss of 0.015525785274803638; accuracy of 98.83391857147217% DiceMetric of 91.26965999603271%\n",
            "Score for fold 1: loss of 0.01767144910991192; accuracy of 98.88797998428345% DiceMetric of 86.97572350502014%\n",
            "Score for fold 1: loss of 0.014588541351258755; accuracy of 98.88877272605896% DiceMetric of 91.53088927268982%\n",
            "Score for fold 1: loss of 0.017506068572402; accuracy of 98.93252849578857% DiceMetric of 88.11689019203186%\n"
          ]
        }
      ]
    }
  ]
}