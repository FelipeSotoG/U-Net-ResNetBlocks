{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeSotoG/U-Net-ResNetBlocks/blob/main/Resnet_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcH2AvTh97gF"
      },
      "source": [
        "##Descarga datos\n",
        "Los datos se encuentran en el drive, por lo que usara gdown para sacarlos directamente y no tener que hacer la coneccion, ya que estamos descargando un zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7GLXIiagwH3",
        "outputId": "73cff789-0c0a-4cd4-be6f-f973c1998b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt\n",
            "To: /content/input.zip\n",
            "100% 597M/597M [00:08<00:00, 74.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uq8I6BfRhogZ"
      },
      "outputs": [],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H9Y2Q3Bce47L"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_jqAPlaMKtpg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hmJoArAEd41C"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  X[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)\n",
        "mas=\"/masks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  Y[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Borrar directorio /input en caso de error"
      ],
      "metadata": {
        "id": "3NcX5DC3VvAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/input"
      ],
      "metadata": {
        "id": "-QywVJIaZjHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6IAoTKTuO5B"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ub5XKwbdAQ32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.3, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6CambWxdEwn"
      },
      "source": [
        "##Resnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6 \n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ],
      "metadata": {
        "id": "Urgfb0zMWlz-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (2, 2), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (2, 2), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (2, 2), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,s"
      ],
      "metadata": {
        "id": "MDQHBprOXZXG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJgrBPxjiV-c",
        "outputId": "654ac7d1-492e-4d4f-d7e6-47c452ef5d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 128, 128, 1)  0           ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 128, 128, 16  80          ['lambda_6[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 128, 128, 16  64         ['conv2d_84[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_84[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 128, 128, 16  1040        ['dropout_28[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 128, 128, 16  80          ['lambda_6[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 128, 128, 16  64         ['conv2d_85[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 128, 128, 16  64         ['conv2d_86[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 128, 128, 16  0           ['batch_normalization_85[0][0]', \n",
            "                                )                                 'batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_28 (ReLU)                (None, 128, 128, 16  0           ['add_28[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooling2D  (None, 64, 64, 16)  0           ['re_lu_28[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 64, 64, 32)   2080        ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 64, 64, 32)  128         ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)           (None, 64, 64, 32)   0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 64, 64, 32)   4128        ['dropout_29[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 64, 64, 32)   2080        ['max_pooling2d_20[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 64, 64, 32)  128         ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 64, 64, 32)  128         ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_88[0][0]', \n",
            "                                                                  'batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_29 (ReLU)                (None, 64, 64, 32)   0           ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooling2D  (None, 32, 32, 32)  0           ['re_lu_29[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 32, 32, 64)   8256        ['max_pooling2d_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 32, 32, 64)  256         ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)           (None, 32, 32, 64)   0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 32, 32, 64)   16448       ['dropout_30[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 32, 32, 64)   8256        ['max_pooling2d_21[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 32, 32, 64)  256         ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 32, 32, 64)  256         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_91[0][0]', \n",
            "                                                                  'batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_30 (ReLU)                (None, 32, 32, 64)   0           ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooling2D  (None, 16, 16, 64)  0           ['re_lu_30[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 16, 16, 128)  32896       ['max_pooling2d_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 16, 16, 128)  512        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)           (None, 16, 16, 128)  0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 16, 16, 128)  65664       ['dropout_31[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 16, 16, 128)  32896       ['max_pooling2d_22[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 16, 16, 128)  512        ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 16, 16, 128)  512        ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_94[0][0]', \n",
            "                                                                  'batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_31 (ReLU)                (None, 16, 16, 128)  0           ['add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooling2D  (None, 8, 8, 128)   0           ['re_lu_31[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 8, 8, 256)    131328      ['max_pooling2d_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 8, 8, 256)    0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 8, 8, 256)    262400      ['dropout_32[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 8, 8, 256)    131328      ['max_pooling2d_23[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_97[0][0]', \n",
            "                                                                  'batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_32 (ReLU)                (None, 8, 8, 256)    0           ['add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 128)  131200     ['re_lu_32[0][0]']               \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
            "                                                                  'batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 16, 16, 128)  131200      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 16, 16, 128)  512        ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 16, 16, 128)  0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 16, 16, 128)  65664       ['dropout_33[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 16, 16, 128)  131200      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 16, 16, 128)  512        ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 16, 16, 128)  512        ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_100[0][0]',\n",
            "                                                                  'batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_33 (ReLU)                (None, 16, 16, 128)  0           ['add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 64)  32832       ['re_lu_33[0][0]']               \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
            "                                                                  'batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 32, 32, 64)   32832       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 32, 32, 64)  256         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 32, 32, 64)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 32, 32, 64)   16448       ['dropout_34[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 32, 32, 64)   32832       ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 32, 32, 64)  256         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 32, 32, 64)  256         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_34 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_103[0][0]',\n",
            "                                                                  'batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_34 (ReLU)                (None, 32, 32, 64)   0           ['add_34[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 32)  8224        ['re_lu_34[0][0]']               \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_10[0][0]',    \n",
            "                                                                  'batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 64, 64, 32)   8224        ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 64, 64, 32)  128         ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 64, 64, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 64, 64, 32)   4128        ['dropout_35[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 64, 64, 32)   8224        ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 64, 64, 32)  128         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 64, 64, 32)  128         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_35 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_106[0][0]',\n",
            "                                                                  'batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_35 (ReLU)                (None, 64, 64, 32)   0           ['add_35[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 16  2064       ['re_lu_35[0][0]']               \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_11[0][0]',    \n",
            "                                )                                 'batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 128, 128, 16  2064        ['concatenate_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 128, 128, 16  64         ['conv2d_108[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_108[0][0]']\n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 128, 128, 16  1040        ['dropout_36[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 128, 128, 16  2064        ['concatenate_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 128, 128, 16  64         ['conv2d_109[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 128, 128, 16  64         ['conv2d_110[0][0]']             \n",
            " Normalization)                 )                                                                 \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, 128, 128, 16  0           ['batch_normalization_109[0][0]',\n",
            "                                )                                 'batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " re_lu_36 (ReLU)                (None, 128, 128, 16  0           ['add_36[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 128, 128, 1)  17          ['re_lu_36[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,318,049\n",
            "Trainable params: 1,313,633\n",
            "Non-trainable params: 4,416\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1\n",
        "\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "#s= inputs\n",
        "#Contraction path\n",
        "c1,z1 = conv_block(s,[16,16])\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "c2,z2 = conv_block(p1,[32,32])\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3,z3 = conv_block(p2,[64,64])\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4,z4 = conv_block(p3,[128,128])\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5,_ = conv_block(p4,[256,256])\n",
        "\n",
        "#Expansive path \n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, z4])\n",
        "c6,_ = conv_block(u6,[128,128])\n",
        " \n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, z3])\n",
        "c7,_ = conv_block(u7,[64,64])\n",
        " \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, z2])\n",
        "c8,_ = conv_block(u8,[32,32])\n",
        "\n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, z1], axis=3)\n",
        "c9,_ = conv_block(u9,[16,16])\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFyLMRezeWO"
      },
      "source": [
        "##Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCB8atJ1zda4",
        "outputId": "6c768df7-2b46-4f4f-c9c2-8c4a235bb9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "124/124 [==============================] - 24s 63ms/step - loss: 0.1116 - accuracy: 0.9783 - DiceMetric: 0.2283 - val_loss: 0.1167 - val_accuracy: 0.9825 - val_DiceMetric: 0.2197\n",
            "Epoch 2/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0347 - accuracy: 0.9879 - DiceMetric: 0.5376 - val_loss: 0.0646 - val_accuracy: 0.9831 - val_DiceMetric: 0.4121\n",
            "Epoch 3/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0216 - accuracy: 0.9886 - DiceMetric: 0.7186 - val_loss: 0.0265 - val_accuracy: 0.9866 - val_DiceMetric: 0.5473\n",
            "Epoch 4/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0163 - accuracy: 0.9889 - DiceMetric: 0.7902 - val_loss: 0.0202 - val_accuracy: 0.9874 - val_DiceMetric: 0.7516\n",
            "Epoch 5/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0132 - accuracy: 0.9890 - DiceMetric: 0.8190 - val_loss: 0.0149 - val_accuracy: 0.9874 - val_DiceMetric: 0.8361\n",
            "Epoch 6/25\n",
            "124/124 [==============================] - 6s 52ms/step - loss: 0.0116 - accuracy: 0.9891 - DiceMetric: 0.8485 - val_loss: 0.0119 - val_accuracy: 0.9878 - val_DiceMetric: 0.8592\n",
            "Epoch 7/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0100 - accuracy: 0.9892 - DiceMetric: 0.8753 - val_loss: 0.0105 - val_accuracy: 0.9880 - val_DiceMetric: 0.8727\n",
            "Epoch 8/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0092 - accuracy: 0.9892 - DiceMetric: 0.8836 - val_loss: 0.0112 - val_accuracy: 0.9875 - val_DiceMetric: 0.8705\n",
            "Epoch 9/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0089 - accuracy: 0.9892 - DiceMetric: 0.8864 - val_loss: 0.0102 - val_accuracy: 0.9880 - val_DiceMetric: 0.8721\n",
            "Epoch 10/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0081 - accuracy: 0.9893 - DiceMetric: 0.9001 - val_loss: 0.0092 - val_accuracy: 0.9880 - val_DiceMetric: 0.8957\n",
            "Epoch 11/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0076 - accuracy: 0.9893 - DiceMetric: 0.9092 - val_loss: 0.0090 - val_accuracy: 0.9880 - val_DiceMetric: 0.8999\n",
            "Epoch 12/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0073 - accuracy: 0.9894 - DiceMetric: 0.9138 - val_loss: 0.0094 - val_accuracy: 0.9878 - val_DiceMetric: 0.8950\n",
            "Epoch 13/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0073 - accuracy: 0.9893 - DiceMetric: 0.9113 - val_loss: 0.0092 - val_accuracy: 0.9878 - val_DiceMetric: 0.8974\n",
            "Epoch 14/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0067 - accuracy: 0.9894 - DiceMetric: 0.9221 - val_loss: 0.0087 - val_accuracy: 0.9879 - val_DiceMetric: 0.9020\n",
            "Epoch 15/25\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.0067 - accuracy: 0.9894 - DiceMetric: 0.9236 - val_loss: 0.0083 - val_accuracy: 0.9880 - val_DiceMetric: 0.9075\n",
            "Epoch 16/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0064 - accuracy: 0.9895 - DiceMetric: 0.9263 - val_loss: 0.0085 - val_accuracy: 0.9881 - val_DiceMetric: 0.9051\n",
            "Epoch 17/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0064 - accuracy: 0.9895 - DiceMetric: 0.9265 - val_loss: 0.0086 - val_accuracy: 0.9879 - val_DiceMetric: 0.9074\n",
            "Epoch 18/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0062 - accuracy: 0.9895 - DiceMetric: 0.9296 - val_loss: 0.0092 - val_accuracy: 0.9881 - val_DiceMetric: 0.8959\n",
            "Epoch 19/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0061 - accuracy: 0.9895 - DiceMetric: 0.9315 - val_loss: 0.0081 - val_accuracy: 0.9881 - val_DiceMetric: 0.9139\n",
            "Epoch 20/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0059 - accuracy: 0.9895 - DiceMetric: 0.9351 - val_loss: 0.0085 - val_accuracy: 0.9880 - val_DiceMetric: 0.9077\n",
            "Epoch 21/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0058 - accuracy: 0.9895 - DiceMetric: 0.9379 - val_loss: 0.0083 - val_accuracy: 0.9881 - val_DiceMetric: 0.9108\n",
            "Epoch 22/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0057 - accuracy: 0.9895 - DiceMetric: 0.9383 - val_loss: 0.0080 - val_accuracy: 0.9882 - val_DiceMetric: 0.9150\n",
            "Epoch 23/25\n",
            "124/124 [==============================] - 6s 51ms/step - loss: 0.0056 - accuracy: 0.9895 - DiceMetric: 0.9400 - val_loss: 0.0081 - val_accuracy: 0.9881 - val_DiceMetric: 0.9155\n",
            "Epoch 24/25\n",
            "124/124 [==============================] - 7s 53ms/step - loss: 0.0055 - accuracy: 0.9895 - DiceMetric: 0.9424 - val_loss: 0.0080 - val_accuracy: 0.9881 - val_DiceMetric: 0.9138\n",
            "Epoch 25/25\n",
            "124/124 [==============================] - 6s 50ms/step - loss: 0.0054 - accuracy: 0.9896 - DiceMetric: 0.9452 - val_loss: 0.0084 - val_accuracy: 0.9879 - val_DiceMetric: 0.9112\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe76e091ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.fit(X_train,Y_train,batch_size=16,epochs=25,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0yz227RzmyI",
        "outputId": "003e6269-c8c9-4890-8c1a-b0b8acbc5821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 0: loss of 0.006995582953095436; accuracy of 98.9439308643341% DiceMetric of 91.55274033546448%\n",
            "['loss', 'accuracy', 'DiceMetric']\n"
          ]
        }
      ],
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oud92q0zgO7x",
        "outputId": "e77e0fe0-001a-48d3-9aa1-bedfbf3869f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy', 'mean_io_u_3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFP-3gQ9BO8f"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5P0-RG0wjzA6"
      },
      "outputs": [],
      "source": [
        "Ypred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "J1ra2EoVycvl",
        "outputId": "e325a6d8-f92c-423d-cd24-66059f2878d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3da3Bb53ng8f9DXEiAIMELaF4kSqIupmylUay6rh13Ek/cbNxsEmenaSdNs3XSdDy70+2k7c60Tvthd7+1u51u05luup6mrXcnm9RNvI5z2a1TO5mum9iJJMuyLFkSKYmmaF5AEiQAEjcC734A3uNDirJkAiBAnec3gyFwcDkvD8558N5fMcaglPKulkYnQCnVWBoElPI4DQJKeZwGAaU8ToOAUh6nQUApj6tbEBCRh0TkvIiMichj9dqPUqo6Uo9+AiLiAy4AHwSuAj8BfsUYc7bmO1NKVcVfp8+9BxgzxlwCEJGvAQ8DmwYBEdEeS0rV37wxpm/jxnoVB3YBk67HVyvbHCLyqIgcF5HjdUqDUmq9ic021isncEPGmMeBx0FzAko1Ur1yAlPAsOvx7so2pVSTqVcQ+AlwSERGRCQIfBJ4pk77UkpVoS7FAWPMmoj8O+AfAB/w18aY1+qxL6VUderSRPiOE6F1AkpthxPGmLs3btQeg0p5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp53JaDgIgMi8j3ReSsiLwmIp+vbO8Rke+JyMXK3+7aJVcpVWvV5ATWgH9vjLkTuBf4TRG5E3gMeM4Ycwh4rvJYKdWkthwEjDHTxpiTlfsp4BywC3gYeKLysieAj1ebSKVU/dRkVWIR2QfcBbwE9BtjpitPzQD913nPo8Cjtdi/Umrrqq4YFJEI8A3gt40xSfdzprzk8aYrDhtjHjfG3L3ZKqlKqe1TVRAQkQDlAPAVY8xTlc2zIjJYeX4QmKsuiUqpeqqmdUCALwPnjDF/6nrqGeCRyv1HgG9uPXlKqXqTco59C28U+Tng/wGvAqXK5j+gXC/wJLAHmAB+2RizeIPP2loilFLvxInNit9bDgK1pEFAqW2xaRDQHoNKeZwGAaU8ToOAUh6nQUApj9MgoJTHaRBQyuM0CCjlcRoElPI4DQK3qJaWFlpa9OtVN1aTocSquYgI5aEdSt2YBoFbkDGGUqlEM3QJV81P84u3KA0A6mZpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTyuFqsS+0TkZRH5duXxiIi8JCJjIvJ3IhKsPplKqXqpRU7g88A51+M/Bv6rMeYgkAA+V4N9KKXqpNqlyXcD/xL4q8pjAT4AfL3ykieAj1ezD6VUfVWbE/gz4Pd4a1XiXmDJGLNWeXwV2LXZG0XkURE5LiLHq0yDUqoKWw4CIvIRYM4Yc2Ir7zfGPG6MuXuzVVKVUtunmjkG7wc+JiIfBtqATuCLQJeI+Cu5gd3AVPXJVErVy5ZzAsaYLxhjdhtj9gGfBJ43xvwq8H3gE5WXPQJ8s+pUKqXqph79BH4f+F0RGaNcR/DlOuxDKVUj0gyz0opI4xOhGk5EdJbk+jqxWR2c9hhUTcGumNTS0tLwhVMavf/tpkFANQ178TX6IvRabkRXIFJNQUSctRO9dhE2muYEVFNoaWnB7/c3RXHAazQnoJqCXUR142Kq7vu1yCHU+vNuBRoEVFNYW1tzFlG1F6fNFdi/9rlSqeRczPa1pVLpup/tphf+tTQIqKZgL2573178fr+fzs5OgsEgfr+fQqFAOp12goaIUCqVyOfz6wKIunkaBFRTsBevDQAiQiAQIBwOc8cdd9DX10csFmN+fp7XX3+dVCpFLpcjEAhQKBRIJBIUi0VKpdJN5wpUmQYB1TTcAcDv99Pd3c3g4CAPPvggIyMjRKNRFhYWOHz4MCsrKxQKBfL5PKlUisuXLzM9Pc3c3Bz5fN4pWqgb0yCgmo47COzZs4d7772XO+64g/b2dpaWlti3bx+5XI5CocDS0hKLi4tEIhEAlpeXKRaLWjR4BzQIqKbS0tJCKBRiz5493H///Xzwgx9kdHSUWCyGz+ejra2Nnp4eJ9tfLBbJZDLcf//9PPPMMwCcP3+edDqtgeAmaRBQTcVWCIZCIXp7e9mzZw8dHR0EAgFEBJ/PR2trq1PuL5VKhMNhfD4ffX199Pb20traSiaTYW1t7QZ7U6CdhVSTsb/cfr+faDTK0NAQbW1tm/YjsDmBQqHA6uoq0WiUAwcOEI1GaW1tvabPgdqc5gSqsLGtWtWW3+8nFArh8/muuZhtk2ImkyGbzbK2tsbKygqJRMJ5bNXze7oVOh9pENgim23Vcmft2QvL7/fT2trqjClws0EgnU6Ty+VYW1tjeXmZubk5VldXKRQKzmfZ7+d692uVXpuunUaLA1ugWcz6McaQz+eJx+OsrKysywW4s/d+v59AIEBnZycAZ86cYWpqyqkQ3Ow7quUFausn7M0Og96JNCewRVrerB+bzc/lck4HIPfxtn9tJaGIkEqlSKfTZLPZTbsVbwwA1QYE24xpuzTbHow70c4MXQ3W0tKCz+cjHA47J6GqDVu8MsawurpKPB53avo36wDU0tJCe3s7e/fuJRAIMD8/73QWcn9mLdhA1NLSQjAYpLOzk97eXm677Tb8fv+OLAqA5gS2ZLOaaq0krL1cLsfS0hLt7e3rBhNtzHb7/X66uroIhUJONt1elLYFoVrufbe1tRGNRtm7dy/GGIrFIouLi+Tz+ar30wgaBLbAPQGGfQwaAGrJZvGnpqbo6Ohwyt02C+4eURgIBBgcHCQajRIMBmlra3OCRqFQqLoLsbsrcyAQoKenh3379vGBD3yAxcVFFhYWuHz5MplMpoZHYPtoENgiESEcDpPP58lmszsuANgTu9laN+yFvbq6yuzsLOfPnycQCBCLxejp6aG9vZ3u7m6KxSJra2tks1my2Syrq6u0tbUxMDBAsVgkm83S3t7OysoKy8vLW/4f3ZV+u3btoq+vj/e///0MDw/zUz/1U5w/f57x8XECgUCNj8T20SCwRXaUW6lUoqWlpSkGrNxss5e7KNPoNG+mVCpRKBRIJpPMzMwQi8UoFotOeiORCNlslkKhQCqVcoKAiDi9C4vFIn6/n3w+v+X/1V0E8Pl8dHZ20t/fz1133cWuXbsYGRkhkUgwOzvr5E52Ig0CW2BPjEwmg4jQ09PjtFfb8mcjToib3ae7xrwZT1xbzl5bW6NQKDA5OUkymaRYLJJOp8nn8xw/fpwrV64wPz+PMYZQKMTly5dZWFhw/q9kMkkmk6mqb4DNmZRKJWdfJ06cYG5ujkKhwOnTpzl16hQrKytNeSxvhgaBLbC/EG1tbU4Z1J64zZAjuBnuYbvNmN5SqUQ2m2V5eRkRYXV1FWMM4XCY6elpXnnlFSYmJkgkEk7RLJFIOE2LtphWi/ED9ljlcjlSqRTj4+Ok02kKhQLj4+NMT09TKBSa8jjeDA0CW9DS0kIgEGDXrl1OM9G5c+colUrrhrI2O/cMPs3Uxm2MoVAoMD8/z4ULF2hvb3dmFbJZ/8nJSZaWloC3JikNh8O0tbWRTCbJ5/Pkcrmqvwdb3LM5v3w+z/PPP+9UFK6trVEsFlldXW2qY/hOVBUERKQL+CvgXYABfh04D/wdsA+4AvyyMSZRVSqbjP21b21tpaenh9HRUWZmZpienl7XZLgTAoHl8/mc++62+kayrQOhUIiWlhane3Aul2NlZcUpetnsujGGXC5HLpe7Zr7Cam2sR/H5fASDQaf+otHHqhrV5gS+CPxfY8wnRCQIhIE/AJ4zxvyRiDwGPEZ5fcJbhj257Ei3/fv3c+rUqR3dbGib1ESkaYo1tgegHT+QyWTWXfCwfqJRm/WvdbrdnYTsLRAIEAqFdnwAgCqCgIhEgfcBnwEwxuSBvIg8DDxQedkTwA+4xYJAsVgkl8sRj8eJxWIATgcV97z5O+HkcP9a2l83n8/nDNFtZBbX/sq6f/Ftmjeqth/A9R67L/z+/n66uroYGBhw6gguXbpENpvd8r6bQTU5gREgDvyNiBwFTgCfB/qNMdOV18wA/Zu9WUQeBR6tYv8NY3+NbPbU/krYwS7bURSo1z6aZSkwy1a41tNm6xy4JzttbW11ZjsaGBhg165d5PN5FhYWmJmZ2RHB/u1UEwT8wDHgt4wxL4nIFyln/R3GGCPXWXHYGPM48DjsvFWJ3XPf226qtpXA5/Nty2CSepx4xphN5/+/1bkrSN39AgKBAL29vfT397N//34efvhhDh8+THt7O7Ozs7z44otMTk6ytra2o49VNUHgKnDVGPNS5fHXKQeBWREZNMZMi8ggMFdtIpuNu8uqrRcYHBxkeHiYeDzu1BjvBJuNfXCvAeA1fr+fYDDI/v37icVivPvd76anp4f+/n4OHDhAb2+vM9dhMBjc0Z2ErC0HAWPMjIhMisioMeY88CBwtnJ7BPijyt9v1iSlTcZmUwOBAH19fezdu5dMJsPrr79ONpvdEa0DGwdA2YU87KCbZk//zbiZYo37NYFAgEgkwj333MMdd9zBxz/+cafp0Rb3crkcfr/febzTj1O1rQO/BXyl0jJwCfgs5eHJT4rI54AJ4Jer3EdTsj3S7CQWg4ODlEolent7yefzzsw27l/UZuyrb23MCexUtv3e7/fT0dEBvNXxyGbbN/6P7uHBNkd33333cfvttxONRgkEAs4YAnfRwX6fzdCSUo2qgoAx5hRw9yZPPVjN5+4Exhiy2Sz5fJ58Pk84HHZWyclkMqTTaYB1E1zs9GmomtXG3IytyBsaGnK6HqdSKfL5vBMI3PUe9qJubW2lq6uL/v5+du/e7Uxy6m7xsX/t0me2OXUn0x6DW2R/XeLxOGfPnmVoaIjh4WF+8Rd/kUuXLvGtb32LxcVFEolyPyn7C2Xbsxtd+baxKGAvBp/P19S5AXvB2jTaTk6230YwGGR0dJS9e/fyS7/0S8TjcS5dusT8/DzpdJpkMukUeVZWVtblEESEwcFBRkZG6OvrIxqNrus/AW997/Pz85w5c8YZT7CTaRCoQqlUIplMMjY2Rk9PD+FwmD179mCMYdeuXc6JZnMDwWDQqTC83kw5223jBB2NTs/bsYE0FAo5j21HIneN/tGjRzlw4AAHDhygp6eHSCTC9PQ0qVTKGfNvxyNkMhlSqRRQrhQ8ePAgIyMjRCKRdU2+7rK/7Sb85ptvOjm+nUyDQBVKpRJzc3M8//zzHDx4kLvuuove3l66uroYHx+nVCqRSCScnmxtbW1OZaKdEbeRFUv24tnYS7BZs7ciQigUcqbzsi0zwWCQ9vZ2isUiPp+PT33qUxw6dIi+vj6nODA+Ps7y8jKBQIBgMEg4HHaCwNTUlDNEeWBggP7+fvr6+jad6dgWAxYXFzl79iyJRKKpA+fN0CBQBWMMmUyG6elpZmZmmJubY2RkhKGhId73vvcRCoVoa2tjeXmZUqlENBp1Jry4fPkyiURiXT/37eLO3gYCAfx+P9lsdl0gaLZab5uT2rNnDw888IDzC28HFwUCAafz1tDQEJFIxKnBDwQC7Nmzh3w+7+QY7OCfQqHA0NAQgLMKcigUorW19Zr1DuwkJleuXOHq1atOPcNOp0GgSvl8nkQiQTweZ35+nkOHDtHd3c273vUuVlZWSKfTzMzMUCwWicViFAoF0um0U0a1fc8bccHZHnHBYLDpV/K1RYG+vj6OHTvG8PAw3d3dzuAiEXGGEff29jpNepbt3r3ZAK/N/ufNXmcHL01NTTEzM8Pq6uotsdSZBoEq2ezh8ePHyWQyHDp0iNtuu42Ojg727t1LLpcjEolQKBTYvXs3ExMTjI2NkUql1g11bdR4g/b2dtrb29ed0M0aCGwNfmdnJ7FYjNtuu41IJOL0b7B9G2zuYLPuwG5v14dg43PGGGZnZ7l69SpPP/004+PjTu5pp9MgUCVbhra10IuLi87SWbbMavsO2AotWx/gznq7a7w39ieo50Vps8vNvHiGuwmvra2N9vZ2pwOPnfLdnYuxA7m2uq+NbMeweDzO5OQkk5OTxOPxpq07eac0CNSAMYaJiQkWFhY4ffo0yWSS7u5uCoUC3d3dBAKBdavqLC0trZsb33ZDtSPm7HTZ7lF89Roea8vTgUCgabO2dmyG7cc/MDBAV1eXsxqx/T/cdR1bcb0AYOsCTp48yY9//GMuXrzoNDXeCjQI1IgdVfjP//zPzMzMcP/999Pa2kowGHR+Sdrb2+no6KCzs5NEIuHMiNPR0cHu3btZWFggmUwSDocByGQyFAoFp5OLbd++ns06I23sSGP7AtgcgO0N586FuN/fLHw+H/39/fT09DiVdu42/Fpf/G5ra2tkMhmuXLnChQsXnFWObhUaBGrE1g288MILxONxjhw5Qm9vr9N05Q4CPT09zMzMOKsY9fb2cvvtt3P58mUAurq6gHKxwd5s+XPjJBb2wnVfCO6LGdb/6tsJMewSXoFA4JrsdDOx/4ff72dgYICenp513Xg3e20t2ZzA6uoqExMTXLhwwWnRuVVoEKghWzfQ0tLCs88+y3vf+15+9md/loMHD1IoFJieniYWi3H77beTy+WIxWI88MADdHV10dPTw0//9E9TKpUYHR2ltbXVWdkmHo8zPj5OPB7n5MmT6ybStEEhGAwSjUadX3Q7dsGWpcPhMMPDw3R2dhKNRslmsyQSCSew2P3Zk74ZKrzsL70tLu3Zs4dYLLZpb8taBwD7+fl8nunpaU6fPs3s7KyTC2jGgLlVGgRqyI4nWF5e5vLlyxw4cIB0Ok1vby/hcNipK9i1axcLCwt0dHQwOjpKNBolFAo53V4PHz5MKBTCGMPi4iLz8/NEo1HnJLQ5g2QySS6Xcy4Se4EUi0Xy+TzGGGcarPb2dkZGRohGo3R1dbG6uuos451Op5mYmHBm8mkG9uL3+/20tbXR0dHhzOyzsea/1mwAKBaLpFIp5ubmGB8fJ5lM7vi5AzajQaDGisUiyWSSU6dOEQwGyWazfPSjH2VoaIjR0VF2797NgQMHGBgYYGlpiSNHjtDV1UUsFnM6qdgsukh5TYP9+/dz7NgxisUin/3sZ8lms6TTaWc+/r6+Pjo7OxkYGCCTyZDJZJzhzHYUnK1ZtxeQ7bRkKypbWlo4f/48J06caOhJ7q63sPUnu3fvZu/evbz//e93ViJydxe274Nri0LvlLtrcDqd5uTJk/zwhz/k6aefZnJysiYzGDcbDQJ1UCwWyWQyvPnmm5w7d46jR48SCAQYHh52KuRGR0fJZDIMDg4SDoeJRCIEg8FrmrdsJZ5tMQgEAhQKBef1mUyGjo4OQqEQXV1dTlHB9mRrb2933u/+7FKp5MwnaIxhaGjIGezU6JPcVpaOjIxw+PBhDh48yNDQEH19fUQiEadJ83qjMrcSCOz7bVY/nU4Tj8d55ZVXuHjxIvPz87dkAAANAnVh19KzXYOPHDmCiLB//35nLb2hoaFrKvRupvOKzfpHIhF6e3uveV1rayvw1knt7n/gHgNvA4MtPhw8eJBkMtnwk9xWXPb19fEzP/MzfOQjH3Fm97GVge6egNezsaXj7Y6tuz+GHeW5sLDAxMQEzz33HG+88Qbz8/O3ZFEANAjUlZ0i++WXX6ZQKHDPPfcQiUTWdXXdavPW9d7jHhbs3rYx2NjmxtXVVebn5zl+/LizgEojBzRFo1FisRj33XcfR48eZd++fYTD4XUXtLtm/u26/G62bbNORO6JYxOJBIuLi/zoRz9ibGyMsbExlpaWbpmZljajQaCObNv+5OQkkUiEpaUlp2luY1m2lm70mTZnsLa2xvLyMvF4nCtXrjA9Pd3Q+Q1aWlqIRCLO0t/9/f10dHTQ0tKybkFS981WgG5sLdg4YYjdhz32tngFb61ZsLKy4vQKPHPmjDMPwa3YIuCmQaCObA3zuXPnWF5e5tlnn+Xw4cO85z3vobOzk9bW1qorst5peqB80qfTaWZnZ3nqqad48cUX+clPfkIqlWrYiW57Be7bt8+Z2nttbY2LFy86owJDoZATCBYXF0kmk1y4cIFUKkUikXDqTxYXF51WmkgkQnd3N/l8nkAgwLFjx5w5IW0OwOfzsby8zOnTpzl58iQvv/yy853Z6eNu1QAAGgS2RS6XY2lpiVdeeYVCoUA4HGb//v309PTQ1tYG1G+e/81+HW0OYHx83LmtrKw0vHnQNrGmUilmZ2dJp9MsLCyQSCScsQL2l/3NN98kkUhw6dIl0um0M1eAz+djaWnJaUoNh8N0dnaytrbmDJseGBhwOvzYOpFEIsGpU6d4/fXXmZiYYGlpySnO3eqkGSKc7LB1B7bCrmJ8+PBh3vve9zpz2Pf396+bwaZWNrv47QmfzWY5ffo03/jGN/jBD37AuXPnGl7pZS/uWCzmtAzYFg33yk5+v5/W1lbGxsaYnZ0llUo58yDY+QNsLb77fTaX0N3dTX9/P0eOHFm35Pji4iLnzp0jmUySSqVu1ez/CWPMNXOCak5gm9jy69WrV3nhhRcoFArs37+fhx56iFgsRl9fX9XBYOOF7yYirKyskEgk+M53vsOFCxf44Q9/yPT0dFNUetkgZRcafeONN5zWgHA4vC4Y+Hw+4vE4y8vLzq+1u/u0/fW2TYk+n49CoeAEiIWFBV599VXntQsLC6TTaRKJRNPPq1APGgS2ic2Gx+Nx56Q7f/48Bw4cYG1tja6uLqfpbiuVhvYi2mwAkL2fTCaZmpriu9/9rtMP/kaDkraTnanJDpiyF3VnZyfBYJBgMOi8dmlpad2kLPb97mBgj6e9qH0+nzMd/MLCgnOc7QxPmUzGUxe/pcWBBmlrayMUCjE6OsrRo0f59Kc/TVdXF52dnXR1dTm9/DbmDDaODrTcXX7dz9l5DuPxOE8++SSvvfYaP/rRj1hZWWFlZaXpTnp3j0Gbld9svoO3W0fAfk4gELgml2D7UdiikW0Z2Nj0eIvS4kAzsfPhXbp0idbWVk6dOkUsFiMajTI8PExHRwe33XabU5bdaGNwsEGgUCg4J7Xt+mpnxDl79iwXLlwgmUw27ZLa7m67pVJp3YIfbteb73/jqErbvGgDRS6Xc163HWtG7gSaE2gw+4vV3t7ujPB78MEHOXToEB/60IeIRCKEw+F1vf6Adctg2WHMKysrXL161Snnp1IpTp8+7WT933jjDVKpVMMrAd+pdzrHgc1JRCIRZ1sul9t0KLbH1D4nICK/A/wGYIBXKS9DNgh8DeilvFz5vzbG7PwpWevEPV7dLmxx6tQpZmZmSCQSTvEAWDcHQGtrqzPRZiaTYXV1ldnZWSYmJnjzzTdZXV1lZWWFyclJFhcXnbbznVjptZX02mNpA0izrPPQjLacExCRXcALwJ3GmIyIPAl8F/gw8JQx5msi8pfAK8aYL93gs/Sb4a11AMLhMMFg0BkfYFfCDQQCdHZ2EgqFiEQijIyM0N3dzdLSEolEgvHxca5cucLU1NS6yi772c2+roCqu7rUCfiBkIgUgDAwDXwA+FTl+SeA/wi8bRBQZfYitfMFrKyssLi4yMTExDWzA/n9fsLh8Lr59t3DiN3TkW3sbquUWzVLk0+JyJ8AbwAZ4FnK2f8lY4ydsfIqsGuz94vIo8CjW93/rcoWD6xsNnvd17qHBd/M52oQUJvZchAQkW7gYWAEWAL+HnjoZt9vjHkceLzyWXpmXsfbXbQ3OwWYXvjq7VQz0fzPA5eNMXFjTAF4Crgf6BIRG1x2A1NVplEpVUfVBIE3gHtFJCzlKtgHgbPA94FPVF7zCPDN6pKolKqnLQcBY8xLwNeBk5SbB1soZ+9/H/hdERmj3Ez45RqkUylVJ9pZSCnv2LSJsDkXn1NKbRsNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8rgbBgER+WsRmRORM65tPSLyPRG5WPnbXdkuIvLnIjImIqdF5Fg9E6+Uqt7N5AT+lmuXHH8MeM4Ycwh4rvIY4BeAQ5Xbo8CXapNMpVS93DAIGGP+CVjcsPlh4InK/SeAj7u2/w9T9iLlZcoHa5VYpVTtbbVOoN8YM125PwP0V+7vAiZdr7ta2XYNEXlURI6LyPEtpkEpVQP+aj/AGGO2sqqwMeZxykuZ66rESjXQVnMCszabX/k7V9k+BQy7Xre7sk0p1aS2GgSeAR6p3H8E+KZr+69VWgnuBZZdxQalVDMyxrztDfgqMA0UKJfxPwf0Um4VuAj8I9BTea0AfwGMA68Cd9/o8yvvM3rTm97qfju+2fUnlYuwobROQKltccIYc/fGjdpjUCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5nAYBpTxOg4BSHqdBQCmPu2EQEJG/FpE5ETnj2vZfROR1ETktIv9bRLpcz31BRMZE5LyIfKheCVdK1cbN5AT+Fnhow7bvAe8yxrwbuAB8AUBE7gQ+CRypvOe/iYivZqlVStXcDYOAMeafgMUN2541xqxVHr5IeQlygIeBrxljcsaYy8AYcE8N06uUqrFa1An8OvB/Kvd3AZOu565Wtl1DRB4VkeMicrwGaVBKbZG/mjeLyB8Ca8BX3ul7jTGPA49XPkdXJVaqQbYcBETkM8BHgAfNW+ubTwHDrpftrmxTSjWpLRUHROQh4PeAjxljVl1PPQN8UkRaRWQEOAT8uPpkKqXq5YY5ARH5KvAAEBORq8B/oNwa0NEyKYgAAARDSURBVAp8T0QAXjTG/BtjzGsi8iRwlnIx4TeNMcV6JV4pVT15KyffwERonYBS2+GEMebujRu1x6BSHqdBQCmP0yCglMdpEFDK4zQIKOVxGgSU8jgNAkp5XFVjB2poHlip/G20GJoON03Hejs5HXs329gUnYUAROT4Zh0ZNB2aDk1HfdOhxQGlPE6DgFIe10xB4PFGJ6BC07GepmO9Wy4dTVMnoJRqjGbKCSilGkCDgFIe1xRBQEQeqqxTMCYij23TPodF5PsiclZEXhORz1e294jI90TkYuVv9zalxyciL4vItyuPR0Tkpcox+TsRCW5DGrpE5OuVNSXOich9jTgeIvI7le/kjIh8VUTatut4XGedjU2PgZT9eSVNp0XkWJ3TUZ/1PowxDb0BPmAc2A8EgVeAO7dhv4PAscr9DsrrJ9wJ/Gfgscr2x4A/3qbj8LvA/wK+XXn8JPDJyv2/BP7tNqThCeA3KveDQNd2Hw/Ks1NfBkKu4/CZ7ToewPuAY8AZ17ZNjwHwYcozbQtwL/BSndPxLwB/5f4fu9JxZ+W6aQVGKteT76b3Ve8T6yb+2fuAf3A9/gLwhQak45vAB4HzwGBl2yBwfhv2vRt4DvgA8O3KSTXv+sLXHaM6pSFaufhkw/ZtPR68NW19D+Uerd8GPrSdxwPYt+Hi2/QYAP8d+JXNXlePdGx47l8BX6ncX3fNAP8A3Hez+2mG4sBNr1VQLyKyD7gLeAnoN8ZMV56aAfq3IQl/Rnni1lLlcS+wZN5a4GU7jskIEAf+plIs+SsRaWebj4cxZgr4E+ANYBpYBk6w/cfD7XrHoJHn7pbW+9hMMwSBhhKRCPAN4LeNMUn3c6YcVuvahioiHwHmjDEn6rmfm+CnnP38kjHmLspjOdbVz2zT8eimvJLVCDAEtHPtMngNsx3H4EaqWe9jM80QBBq2VoGIBCgHgK8YY56qbJ4VkcHK84PAXJ2TcT/wMRG5AnyNcpHgi0CXiNgBXttxTK4CV40xL1Uef51yUNju4/HzwGVjTNwYUwCeonyMtvt4uF3vGGz7ueta7+NXKwGp6nQ0QxD4CXCoUvsbpLyg6TP13qmU50r/MnDOGPOnrqeeAR6p3H+Ecl1B3RhjvmCM2W2M2Uf5f3/eGPOrwPeBT2xjOmaASREZrWx6kPLU8dt6PCgXA+4VkXDlO7Lp2NbjscH1jsEzwK9VWgnuBZZdxYaaq9t6H/Ws5HkHFSAfplw7Pw784Tbt8+coZ+tOA6cqtw9TLo8/B1wE/hHo2cbj8ABvtQ7sr3yRY8DfA63bsP/3AMcrx+RpoLsRxwP4T8DrwBngf1Ku9d6W4wF8lXJdRIFy7uhz1zsGlCtw/6Jy3r4K3F3ndIxRLvvb8/UvXa//w0o6zgO/8E72pd2GlfK4ZigOKKUaSIOAUh6nQUApj9MgoJTHaRBQyuM0CCjlcRoElPK4/w9krshVzdcQKwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(np.reshape(Ypred[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()\n",
        "plt.imshow(np.reshape(Y_test[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ikB_eI_ZmVtq"
      },
      "outputs": [],
      "source": [
        "def dice(true_mask, pred_mask):\n",
        "    \"\"\"\n",
        "        Computes the Dice coefficient.\n",
        "        Args:\n",
        "            true_mask : Array of arbitrary shape.\n",
        "            pred_mask : Array with the same shape than true_mask.  \n",
        "        \n",
        "        Returns:\n",
        "            A scalar representing the Dice coefficient between the two segmentations. \n",
        "        \n",
        "    \"\"\"\n",
        "    non_seg_score=1.0\n",
        "    if type(pred_mask) != np.ndarray:\n",
        "      t = torch.Tensor([0.5])\n",
        "      pred_mask=(pred_mask > t)\n",
        "    else:\n",
        "      pred_mask[pred_mask>=0.5]=1\n",
        "      pred_mask[pred_mask<0.5]=0\n",
        "\n",
        "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
        "    im_sum = true_mask.sum() + pred_mask.sum()\n",
        "    if im_sum == 0:\n",
        "        return non_seg_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2. * intersection.sum() / im_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBVFzRQmXI-",
        "outputId": "d62152c7-9db1-46df-b82b-67f6ccc34aa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.043468708411671"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "diceaux=dice(Y_test[160],Ypred[160])\n",
        "diceaux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc2Sj8PPuJBv"
      },
      "source": [
        "## Model Fit Kfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Fh7g3mmhuNPV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kj7ESdJAuOaW"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 epochs"
      ],
      "metadata": {
        "id": "erWVgdGfhXKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7gaF3LTvOU-",
        "outputId": "4ea02850-9c2a-43dc-bdaa-ba664071361a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.013711574487388134; accuracy of 98.9607036113739% DiceMetric of 89.64645862579346%\n",
            "Score for fold 2: loss of 0.016491202637553215; accuracy of 98.84399175643921% DiceMetric of 89.99229669570923%\n",
            "Score for fold 3: loss of 0.02911568433046341; accuracy of 98.89013767242432% DiceMetric of 84.47749614715576%\n",
            "Score for fold 4: loss of 0.024804146960377693; accuracy of 98.87792468070984% DiceMetric of 87.79023885726929%\n",
            "Score for fold 5: loss of 0.024883681908249855; accuracy of 98.93229007720947% DiceMetric of 85.4052186012268%\n"
          ]
        }
      ],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 epochs"
      ],
      "metadata": {
        "id": "uOWim3VxhZsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN7om-UlhbP9",
        "outputId": "e8e570de-1955-4c6c-d911-39ed9447879b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.035441458225250244; accuracy of 98.93199801445007% DiceMetric of 88.60492706298828%\n",
            "Score for fold 2: loss of 0.0388910211622715; accuracy of 98.80289435386658% DiceMetric of 87.82492280006409%\n",
            "Score for fold 3: loss of 0.04442983493208885; accuracy of 98.86915683746338% DiceMetric of 83.60141515731812%\n",
            "Score for fold 4: loss of 0.03743252903223038; accuracy of 98.86673092842102% DiceMetric of 87.42475509643555%\n",
            "Score for fold 5: loss of 0.036050498485565186; accuracy of 98.92160296440125% DiceMetric of 85.15322208404541%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Resnet V4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKcL0K+VFIzPfpv/BZEEAK",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}