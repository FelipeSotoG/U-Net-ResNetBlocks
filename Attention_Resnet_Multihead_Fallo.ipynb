{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeSotoG/U-Net-ResNetBlocks/blob/main/Attention_Resnet_Multihead_Fallo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcH2AvTh97gF"
      },
      "source": [
        "##Descarga datos\n",
        "Los datos se encuentran en el drive, por lo que usara gdown para sacarlos directamente y no tener que hacer la coneccion, ya que estamos descargando un zip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7GLXIiagwH3",
        "outputId": "5b22872f-2584-4d4e-f42c-bdab30c3e57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt\n",
            "To: /content/input.zip\n",
            "100% 597M/597M [00:02<00:00, 205MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1f3hc0IdnyN60NjGoPO9Za9Vnmj9pk3zt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uq8I6BfRhogZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0035d658-5b67-4f53-c53d-b359f662ed70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace input/train/masks/radiopaedia_10_85902_3_397.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H9Y2Q3Bce47L"
      },
      "outputs": [],
      "source": [
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_jqAPlaMKtpg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hmJoArAEd41C"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "src=\"/content/input/train\"\n",
        "imag=\"/images/\"\n",
        "X=np.zeros((len(glob.glob(src+imag+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+imag+\"*.png\"))):\n",
        "  X[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)\n",
        "mas=\"/masks/\"\n",
        "Y=np.zeros((len(glob.glob(src+mas+\"*.png\")),IMG_WIDTH,IMG_HEIGHT,1))\n",
        "for i,x in enumerate(sorted(glob.glob(src+mas+\"*.png\"))):\n",
        "  Y[i]=resize(iio.imread(x),(IMG_WIDTH,IMG_HEIGHT,1),mode=\"constant\",preserve_range=True)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Borrar directorio /input en caso de error"
      ],
      "metadata": {
        "id": "3NcX5DC3VvAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/input"
      ],
      "metadata": {
        "id": "-QywVJIaZjHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6IAoTKTuO5B"
      },
      "source": [
        "##Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ub5XKwbdAQ32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.3, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6CambWxdEwn"
      },
      "source": [
        "##Resnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "FlAI4R5nZPxD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DiceMetric(y_true, y_pred):\n",
        "  smooth=1e-6 \n",
        "  gama=2\n",
        "  y_true, y_pred = tf.cast(\n",
        "      y_true, dtype=tf.float32), tf.cast(y_pred, tf.float32)\n",
        "  nominator = 2 * \\\n",
        "      tf.reduce_sum(tf.multiply(y_pred, y_true)) + smooth\n",
        "  denominator = tf.reduce_sum(\n",
        "      y_pred ** gama) + tf.reduce_sum(y_true ** gama) + smooth\n",
        "  result = tf.divide(nominator, denominator)\n",
        "  return result\n",
        "def DiceLoss(y_true, y_pred):\n",
        "      result= 1- DiceMetric(y_true, y_pred)\n",
        "      return result"
      ],
      "metadata": {
        "id": "Urgfb0zMWlz-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(X,f,d=0.1,group=1):\n",
        "  c = tf.keras.layers.Conv2D(f[0], (2, 2), activation='relu', kernel_initializer='he_normal', padding='same',groups=group)(X)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  c = tf.keras.layers.Dropout(d)(c)\n",
        "  c = tf.keras.layers.Conv2D(f[1], (2, 2), kernel_initializer='he_normal', padding='same', groups=group)(c)\n",
        "  c = tf.keras.layers.BatchNormalization(axis=3)(c)\n",
        "  s = tf.keras.layers.Conv2D(f[1], (2, 2), kernel_initializer='he_normal', padding='same')(X)\n",
        "  s = tf.keras.layers.BatchNormalization(axis=3)(s)\n",
        "  c = tf.keras.layers.Add()([c,s])\n",
        "  c = tf.keras.layers.ReLU()(c)\n",
        "  return c,s"
      ],
      "metadata": {
        "id": "MDQHBprOXZXG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJgrBPxjiV-c",
        "outputId": "175167e7-e5be-475e-fb5d-76f1a9257942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 128, 128, 1)  0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 128, 128, 16  80          ['lambda_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 128, 128, 16  64         ['conv2d_56[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_54[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 128, 128, 16  1040        ['dropout_18[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 128, 128, 16  80          ['lambda_3[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 128, 128, 16  64         ['conv2d_57[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 128, 128, 16  64         ['conv2d_58[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 128, 128, 16  0           ['batch_normalization_55[0][0]', \n",
            "                                )                                 'batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_18 (ReLU)                (None, 128, 128, 16  0           ['add_18[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 16)  0           ['re_lu_18[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 64, 64, 32)   2080        ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 64, 64, 32)  128         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 64, 64, 32)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 64, 64, 32)   4128        ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 64, 64, 32)   2080        ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 64, 64, 32)  128         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 64, 64, 32)  128         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_58[0][0]', \n",
            "                                                                  'batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_19 (ReLU)                (None, 64, 64, 32)   0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 32)  0           ['re_lu_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 32, 32, 64)   8256        ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 32, 32, 64)  256         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 32, 32, 64)   0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 32, 32, 64)   16448       ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 32, 32, 64)   8256        ['max_pooling2d_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 32, 32, 64)  256         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 32, 32, 64)  256         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_61[0][0]', \n",
            "                                                                  'batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_20 (ReLU)                (None, 32, 32, 64)   0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 64)  0           ['re_lu_20[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 16, 16, 128)  32896       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 16, 16, 128)  512        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 16, 16, 128)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 16, 16, 128)  65664       ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 16, 16, 128)  32896       ['max_pooling2d_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 16, 16, 128)  512        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 16, 16, 128)  512        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_64[0][0]', \n",
            "                                                                  'batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_21 (ReLU)                (None, 16, 16, 128)  0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 128)   0           ['re_lu_21[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 8, 8, 256)    131328      ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)           (None, 8, 8, 256)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 8, 8, 256)    262400      ['dropout_22[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 8, 8, 256)    131328      ['max_pooling2d_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_67[0][0]', \n",
            "                                                                  'batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_22 (ReLU)                (None, 8, 8, 256)    0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 128)  131200     ['re_lu_22[0][0]']               \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (MultiH  (None, 16, 16, 128)  18632      ['batch_normalization_65[0][0]', \n",
            " eadAttention)                                                    'batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 16, 16, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
            "                                                                  'multi_head_attention_8[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 16, 16, 128)  131200      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 16, 16, 128)  512        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)           (None, 16, 16, 128)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 16, 16, 128)  65664       ['dropout_23[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 16, 16, 128)  131200      ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 16, 16, 128)  512        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 16, 16, 128)  512        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_70[0][0]', \n",
            "                                                                  'batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_23 (ReLU)                (None, 16, 16, 128)  0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 64)  32832       ['re_lu_23[0][0]']               \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (MultiH  (None, 32, 32, 64)  9352        ['batch_normalization_62[0][0]', \n",
            " eadAttention)                                                    'batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_9[0][0]',     \n",
            "                                                                  'multi_head_attention_9[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 32, 32, 64)   32832       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 32, 32, 64)  256         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)           (None, 32, 32, 64)   0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 32, 32, 64)   16448       ['dropout_24[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 32, 32, 64)   32832       ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 32, 32, 64)  256         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 32, 32, 64)  256         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_73[0][0]', \n",
            "                                                                  'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_24 (ReLU)                (None, 32, 32, 64)   0           ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 32)  8224        ['re_lu_24[0][0]']               \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (Multi  (None, 64, 64, 32)  4712        ['batch_normalization_59[0][0]', \n",
            " HeadAttention)                                                   'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 64, 64, 64)   0           ['conv2d_transpose_10[0][0]',    \n",
            "                                                                  'multi_head_attention_10[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 64, 64, 32)   8224        ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 64, 64, 32)  128         ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_25 (Dropout)           (None, 64, 64, 32)   0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 64, 64, 32)   4128        ['dropout_25[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 64, 64, 32)   8224        ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 64, 64, 32)  128         ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 64, 64, 32)  128         ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_76[0][0]', \n",
            "                                                                  'batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_25 (ReLU)                (None, 64, 64, 32)   0           ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 16  2064       ['re_lu_25[0][0]']               \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (Multi  (None, 128, 128, 16  2392       ['batch_normalization_56[0][0]', \n",
            " HeadAttention)                 )                                 'batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 128, 128, 32  0           ['conv2d_transpose_11[0][0]',    \n",
            "                                )                                 'multi_head_attention_11[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 128, 128, 16  2064        ['concatenate_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 128, 128, 16  64         ['conv2d_80[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)           (None, 128, 128, 16  0           ['batch_normalization_78[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 128, 128, 16  1040        ['dropout_26[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 128, 128, 16  2064        ['concatenate_11[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 128, 128, 16  64         ['conv2d_81[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 128, 128, 16  64         ['conv2d_82[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 128, 128, 16  0           ['batch_normalization_79[0][0]', \n",
            "                                )                                 'batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " re_lu_26 (ReLU)                (None, 128, 128, 16  0           ['add_26[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 128, 128, 1)  17          ['re_lu_26[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,353,137\n",
            "Trainable params: 1,348,721\n",
            "Non-trainable params: 4,416\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNELS = 1\n",
        "nheads=8\n",
        "\n",
        "#Build the model\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "#s= inputs\n",
        "#Contraction path\n",
        "c1,z1 = conv_block(s,[16,16])\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "\n",
        "c2,z2 = conv_block(p1,[32,32])\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "c3,z3 = conv_block(p2,[64,64],0.2)\n",
        "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        " \n",
        "c4,z4 = conv_block(p3,[128,128],0.2)\n",
        "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        " \n",
        "c5,z5 = conv_block(p4,[256,256],0.3)\n",
        "\n",
        "#Expansive path \n",
        "m1= tf.keras.layers.MultiHeadAttention(num_heads=nheads, key_dim=3, attention_axes=(1, 2))(z4,z5)\n",
        "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "u6 = tf.keras.layers.concatenate([u6, m1])\n",
        "c6,z6 = conv_block(u6,[128,128],0.2)\n",
        "\n",
        "m2= tf.keras.layers.MultiHeadAttention(num_heads=nheads, key_dim=3, attention_axes=(1, 2))(z3,z6)\n",
        "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "u7 = tf.keras.layers.concatenate([u7, m2])\n",
        "c7,z7 = conv_block(u7,[64,64],0.2)\n",
        "\n",
        "m3= tf.keras.layers.MultiHeadAttention(num_heads=nheads, key_dim=3, attention_axes=(1, 2))(z2,z7) \n",
        "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "u8 = tf.keras.layers.concatenate([u8, m3])\n",
        "c8,z8 = conv_block(u8,[32,32])\n",
        "\n",
        "m4= tf.keras.layers.MultiHeadAttention(num_heads=nheads, key_dim=3, attention_axes=(1, 2))(z1,z8) \n",
        "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "u9 = tf.keras.layers.concatenate([u9, m4], axis=3)\n",
        "c9,_ = conv_block(u9,[16,16])\n",
        " \n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        " \n",
        "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFyLMRezeWO"
      },
      "source": [
        "##Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kCB8atJ1zda4",
        "outputId": "b756bae3-3033-4712-feaf-48d7bd9c51c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5fc984f86343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/multi_head_attention_7/einsum/Einsum' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-15-669d5f65e92f>\", line 1, in <module>\n      model.fit(X_train,Y_train,batch_size=20,epochs=25,validation_split=0.2)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/multi_head_attention.py\", line 511, in call\n      query, key, value, attention_mask, training)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/multi_head_attention.py\", line 473, in _compute_attention\n      query)\nNode: 'model_1/multi_head_attention_7/einsum/Einsum'\nOOM when allocating tensor with shape[10,8,4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/multi_head_attention_7/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_19797]"
          ]
        }
      ],
      "source": [
        "model.fit(X_train,Y_train,batch_size=10,epochs=25,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0yz227RzmyI"
      },
      "outputs": [],
      "source": [
        "scores= model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f'Score for fold {0}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "print(model.metrics_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names)"
      ],
      "metadata": {
        "id": "oud92q0zgO7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFP-3gQ9BO8f"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5P0-RG0wjzA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b779236f-752a-48c9-8c09-f47c6b84d382"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-50720b20008d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mYpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/multi_head_attention_23/einsum/Einsum' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-33-50720b20008d>\", line 1, in <module>\n      Ypred=model.predict(X_test)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/multi_head_attention.py\", line 511, in call\n      query, key, value, attention_mask, training)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/multi_head_attention.py\", line 473, in _compute_attention\n      query)\nNode: 'model_4/multi_head_attention_23/einsum/Einsum'\nOOM when allocating tensor with shape[32,4,4096,16384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_4/multi_head_attention_23/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_110611]"
          ]
        }
      ],
      "source": [
        "Ypred=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1ra2EoVycvl"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.reshape(Ypred[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()\n",
        "plt.imshow(np.reshape(Y_test[160],(128,128)), cmap=plt.cm.gray)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikB_eI_ZmVtq"
      },
      "outputs": [],
      "source": [
        "def dice(true_mask, pred_mask):\n",
        "    \"\"\"\n",
        "        Computes the Dice coefficient.\n",
        "        Args:\n",
        "            true_mask : Array of arbitrary shape.\n",
        "            pred_mask : Array with the same shape than true_mask.  \n",
        "        \n",
        "        Returns:\n",
        "            A scalar representing the Dice coefficient between the two segmentations. \n",
        "        \n",
        "    \"\"\"\n",
        "    non_seg_score=1.0\n",
        "    if type(pred_mask) != np.ndarray:\n",
        "      t = torch.Tensor([0.5])\n",
        "      pred_mask=(pred_mask > t)\n",
        "    else:\n",
        "      pred_mask[pred_mask>=0.5]=1\n",
        "      pred_mask[pred_mask<0.5]=0\n",
        "\n",
        "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
        "    im_sum = true_mask.sum() + pred_mask.sum()\n",
        "    if im_sum == 0:\n",
        "        return non_seg_score\n",
        "\n",
        "    # Compute Dice coefficient\n",
        "    intersection = np.logical_and(true_mask, pred_mask)\n",
        "    return 2. * intersection.sum() / im_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBVFzRQmXI-",
        "outputId": "51ce2c6f-6865-46b0-fa59-3128c9f76d8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9357399154707194"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "diceaux=dice(Y_test[160],Ypred[160])\n",
        "diceaux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc2Sj8PPuJBv"
      },
      "source": [
        "## Model Fit Kfold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh7g3mmhuNPV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import absolute\n",
        "from numpy import sqrt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj7ESdJAuOaW"
      },
      "outputs": [],
      "source": [
        "cv = KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25 epochs"
      ],
      "metadata": {
        "id": "erWVgdGfhXKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7gaF3LTvOU-",
        "outputId": "9618694e-c8fb-4139-9afc-63238c7bd3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.010589624755084515; accuracy of 98.96852374076843% DiceMetric of 90.11987447738647%\n",
            "Score for fold 2: loss of 0.017074687406420708; accuracy of 98.8399863243103% DiceMetric of 88.72661590576172%\n",
            "Score for fold 3: loss of 0.019004367291927338; accuracy of 98.89352321624756% DiceMetric of 85.86874604225159%\n",
            "Score for fold 4: loss of 0.021750498563051224; accuracy of 98.8770842552185% DiceMetric of 87.11013793945312%\n",
            "Score for fold 5: loss of 0.02564629353582859; accuracy of 98.92171621322632% DiceMetric of 84.32435989379883%\n"
          ]
        }
      ],
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=25,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "50 epochs"
      ],
      "metadata": {
        "id": "uOWim3VxhZsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_ACCURACY = []\n",
        "VALIDAITON_LOSS = []\n",
        "nfold=1\n",
        "for train_index, val_index in cv.split(X,Y):\n",
        "  model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',DiceMetric])\n",
        "\n",
        "  X_fold=X[train_index,:,:]\n",
        "  Y_fold=Y[train_index,:,:]\n",
        "  \n",
        "  model.fit(X_fold,Y_fold,batch_size=16,epochs=50,validation_split=0.2,verbose=0)\n",
        "\n",
        "  Xtest_fold=X[val_index,:,:]\n",
        "  Ytest_fold=Y[val_index,:,:]\n",
        "  scores= model.evaluate(Xtest_fold, Ytest_fold, verbose=0)\n",
        "  print(f'Score for fold {nfold}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% {model.metrics_names[2]} of {scores[2]*100}%')\n",
        "  nfold+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN7om-UlhbP9",
        "outputId": "4b03165d-5f5d-4372-d4ff-215ec6cb8470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for fold 1: loss of 0.03275185450911522; accuracy of 98.92805218696594% DiceMetric of 86.43335103988647%\n",
            "Score for fold 2: loss of 0.04437226057052612; accuracy of 98.79524111747742% DiceMetric of 86.79052591323853%\n",
            "Score for fold 3: loss of 0.04615918546915054; accuracy of 98.85607361793518% DiceMetric of 81.74516558647156%\n",
            "Score for fold 4: loss of 0.037034377455711365; accuracy of 98.85841608047485% DiceMetric of 85.59434413909912%\n",
            "Score for fold 5: loss of 0.04235682263970375; accuracy of 98.91199469566345% DiceMetric of 83.59041213989258%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Attention Resnet Multihead-Fallo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXV7RCj/QVnvMEjrXU1KUb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}